{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_registered</th>\n",
       "      <th>age_registered</th>\n",
       "      <th>dialysis_session_count</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>underlying_disease</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>chagas</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>transfusion_count</th>\n",
       "      <th>gestation</th>\n",
       "      <th>prior_transplant</th>\n",
       "      <th>c_pra</th>\n",
       "      <th>hla_a1</th>\n",
       "      <th>hla_a2</th>\n",
       "      <th>hla_b1</th>\n",
       "      <th>hla_b2</th>\n",
       "      <th>hla_dr1</th>\n",
       "      <th>hla_dr2</th>\n",
       "      <th>dr_00</th>\n",
       "      <th>b_00</th>\n",
       "      <th>a_00</th>\n",
       "      <th>anti_hbc</th>\n",
       "      <th>anti_hcv</th>\n",
       "      <th>hbs_ag</th>\n",
       "      <th>event</th>\n",
       "      <th>days_waiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Branca</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>waiting</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-11-03</td>\n",
       "      <td>58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Branca</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>homozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>died_waiting</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-13</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Branca</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>removed</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-03</td>\n",
       "      <td>52</td>\n",
       "      <td>17.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Branca</td>\n",
       "      <td>diabetes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>removed</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-07-05</td>\n",
       "      <td>67</td>\n",
       "      <td>68.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Parda</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>heterozygous</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>died_waiting</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_registered  age_registered  ...         event days_waiting\n",
       "0      2017-06-29              67  ...       waiting          392\n",
       "1      2008-11-03              58  ...  died_waiting         2066\n",
       "2      2010-07-13              51  ...       removed          365\n",
       "3      2011-10-03              52  ...       removed          365\n",
       "4      2006-07-05              67  ...  died_waiting          194\n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('waitlist_kidney_brazil_prepared_sensitive.csv', encoding='iso-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_registered</th>\n",
       "      <th>dialysis_session_count</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>chagas</th>\n",
       "      <th>transfusion_count</th>\n",
       "      <th>gestation</th>\n",
       "      <th>prior_transplant</th>\n",
       "      <th>c_pra</th>\n",
       "      <th>hla_a1</th>\n",
       "      <th>hla_a2</th>\n",
       "      <th>hla_b1</th>\n",
       "      <th>hla_b2</th>\n",
       "      <th>hla_dr1</th>\n",
       "      <th>hla_dr2</th>\n",
       "      <th>anti_hbc</th>\n",
       "      <th>anti_hcv</th>\n",
       "      <th>hbs_ag</th>\n",
       "      <th>days_waiting</th>\n",
       "      <th>a_00_homozygous</th>\n",
       "      <th>b_00_homozygous</th>\n",
       "      <th>blood_type_AB</th>\n",
       "      <th>blood_type_B</th>\n",
       "      <th>blood_type_O</th>\n",
       "      <th>underlying_disease_glomerulonephritis</th>\n",
       "      <th>underlying_disease_hypertension</th>\n",
       "      <th>underlying_disease_other</th>\n",
       "      <th>underlying_disease_pyelonephritis</th>\n",
       "      <th>dr_00_homozygous</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>date_registered</th>\n",
       "      <th>date_transplanted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-92.579005</td>\n",
       "      <td>-58.700625</td>\n",
       "      <td>-2.698233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.301101</td>\n",
       "      <td>-0.786908</td>\n",
       "      <td>-0.324948</td>\n",
       "      <td>-23.323957</td>\n",
       "      <td>-11.906148</td>\n",
       "      <td>-62.613581</td>\n",
       "      <td>-47.724847</td>\n",
       "      <td>-78.362652</td>\n",
       "      <td>-16.089739</td>\n",
       "      <td>-27.778388</td>\n",
       "      <td>-0.074830</td>\n",
       "      <td>-0.025542</td>\n",
       "      <td>-0.016921</td>\n",
       "      <td>-1829.826132</td>\n",
       "      <td>-0.356975</td>\n",
       "      <td>-0.163960</td>\n",
       "      <td>-0.175674</td>\n",
       "      <td>-0.492531</td>\n",
       "      <td>-1.372507</td>\n",
       "      <td>-0.647694</td>\n",
       "      <td>-0.918396</td>\n",
       "      <td>-1.050267</td>\n",
       "      <td>-0.081876</td>\n",
       "      <td>-0.150369</td>\n",
       "      <td>Amarela</td>\n",
       "      <td>M</td>\n",
       "      <td>10959.0</td>\n",
       "      <td>2004-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.041522</td>\n",
       "      <td>-5.766981</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.337311</td>\n",
       "      <td>-0.492080</td>\n",
       "      <td>-0.088624</td>\n",
       "      <td>-12.042648</td>\n",
       "      <td>-4.173059</td>\n",
       "      <td>10.889024</td>\n",
       "      <td>-4.801405</td>\n",
       "      <td>11.216672</td>\n",
       "      <td>7.379731</td>\n",
       "      <td>7.870809</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>3727.832965</td>\n",
       "      <td>-0.076394</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>-0.030686</td>\n",
       "      <td>-0.085568</td>\n",
       "      <td>-0.326738</td>\n",
       "      <td>-0.188164</td>\n",
       "      <td>-0.138999</td>\n",
       "      <td>0.680715</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>-0.037583</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>10962.0</td>\n",
       "      <td>2012-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.958478</td>\n",
       "      <td>-11.766981</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662689</td>\n",
       "      <td>0.507920</td>\n",
       "      <td>-0.088624</td>\n",
       "      <td>52.957352</td>\n",
       "      <td>-4.173059</td>\n",
       "      <td>48.889024</td>\n",
       "      <td>18.198595</td>\n",
       "      <td>26.216672</td>\n",
       "      <td>10.379731</td>\n",
       "      <td>4.870809</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>2781.832965</td>\n",
       "      <td>-0.076394</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>-0.030686</td>\n",
       "      <td>-0.085568</td>\n",
       "      <td>0.673262</td>\n",
       "      <td>-0.188164</td>\n",
       "      <td>0.861001</td>\n",
       "      <td>-0.319285</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>-0.037583</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>10962.0</td>\n",
       "      <td>2009-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.041522</td>\n",
       "      <td>-7.766981</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.337311</td>\n",
       "      <td>0.507920</td>\n",
       "      <td>-0.088624</td>\n",
       "      <td>-12.042648</td>\n",
       "      <td>-4.173059</td>\n",
       "      <td>11.889024</td>\n",
       "      <td>19.198595</td>\n",
       "      <td>26.216672</td>\n",
       "      <td>2.379731</td>\n",
       "      <td>-0.129191</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>729.832965</td>\n",
       "      <td>-0.076394</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>-0.030686</td>\n",
       "      <td>-0.085568</td>\n",
       "      <td>0.673262</td>\n",
       "      <td>0.811836</td>\n",
       "      <td>-0.138999</td>\n",
       "      <td>-0.319285</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>-0.037583</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>10962.0</td>\n",
       "      <td>2004-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.041522</td>\n",
       "      <td>-4.766981</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662689</td>\n",
       "      <td>-0.492080</td>\n",
       "      <td>-0.088624</td>\n",
       "      <td>-12.042648</td>\n",
       "      <td>23.826941</td>\n",
       "      <td>13.889024</td>\n",
       "      <td>33.198595</td>\n",
       "      <td>26.216672</td>\n",
       "      <td>3.379731</td>\n",
       "      <td>4.870809</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>819.832965</td>\n",
       "      <td>-0.076394</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>-0.030686</td>\n",
       "      <td>-0.085568</td>\n",
       "      <td>-0.326738</td>\n",
       "      <td>0.811836</td>\n",
       "      <td>-0.138999</td>\n",
       "      <td>-0.319285</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>-0.037583</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>10962.0</td>\n",
       "      <td>2004-07-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_registered  dialysis_session_count  ...  date_registered  date_transplanted\n",
       "0      -92.579005              -58.700625  ...          10959.0         2004-01-21\n",
       "1       -0.041522               -5.766981  ...          10962.0         2012-06-20\n",
       "2        7.958478              -11.766981  ...          10962.0         2009-11-17\n",
       "3       -1.041522               -7.766981  ...          10962.0         2004-04-05\n",
       "4       -6.041522               -4.766981  ...          10962.0         2004-07-04\n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_clean = df[df['event'] == 'transplanted'].copy()\n",
    "    df_clean.drop(columns=['event'], inplace=True)\n",
    "    df_clean['date_registered'] = \\\n",
    "        pd.to_datetime(df['date_registered']).astype(int) / (1e9 * 3600 * 24)\n",
    "    df_clean['date_transplanted'] = \\\n",
    "        pd.to_datetime(df['date_registered']) + pd.to_timedelta(df_clean['days_waiting'], 'days')\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def onehot_encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_onehot = pd.get_dummies(\n",
    "        df,\n",
    "        columns=list(set([\n",
    "            'sex',\n",
    "            'race',\n",
    "            'underlying_disease',\n",
    "            'blood_type',\n",
    "            'dr_00',\n",
    "            'b_00',\n",
    "            'a_00'\n",
    "        ]) & set(df.columns)),\n",
    "        drop_first=True\n",
    "    )\n",
    "    df_onehot['race'] = df['race']\n",
    "    df_onehot['sex'] = df['sex']\n",
    "    return df_onehot\n",
    "\n",
    "\n",
    "def train_test_split(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    N = df.shape[0]\n",
    "    N_train = N * 80 // 100\n",
    "    df.sort_values(by='date_registered', inplace=True, ignore_index=True)\n",
    "    return df.iloc[:N_train], df[N_train:]\n",
    "\n",
    "\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "\n",
    "\n",
    "def remove_correlation(df: pd.DataFrame, *, correlation_remover = None) -> pd.DataFrame:\n",
    "    sensitive_features = ['sex_M', 'race_Branca', 'race_Parda', 'race_Negra']\n",
    "    if correlation_remover is None:\n",
    "        correlation_remover = CorrelationRemover(sensitive_feature_ids=sensitive_features)\n",
    "    meta = ['race', 'sex', 'date_registered', 'date_transplanted']\n",
    "    mesa = df.drop(columns=meta) # Vide Cheal, Joe. \"What is the opposite of meta?.\" ANLP Acuity Vol 2 (2011).\n",
    "    data = correlation_remover.fit_transform(mesa)\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(data, index=mesa.index, columns=[col for col in mesa.columns if not col in sensitive_features]),\n",
    "            df[meta],\n",
    "            # df[sensitive_features] # Não faz sentido adicionar de volta, né?\n",
    "        ],\n",
    "        axis=1\n",
    "    ), correlation_remover\n",
    "\n",
    "\n",
    "def augment_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df\n",
    "    sensitive_features = ['sex', 'race']\n",
    "    groups = df.groupby(sensitive_features)\n",
    "    big = groups.count().max().max()\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.concat([data, data.sample(big - data.shape[0], replace=True, random_state=1729)])\n",
    "            for _, data in groups\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df_people = onehot_encode(clean(df))\n",
    "df_people_train, df_people_test = train_test_split(df_people)\n",
    "df_people_train_uncorrelated, remover = remove_correlation(augment_df(df_people_train))\n",
    "df_people_test_uncorrelated, _ = remove_correlation(df_people_test, correlation_remover=remover)\n",
    "df_people_train_uncorrelated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_registered_a</th>\n",
       "      <th>age_registered_a</th>\n",
       "      <th>dialysis_session_count_a</th>\n",
       "      <th>diabetes_a</th>\n",
       "      <th>chagas_a</th>\n",
       "      <th>transfusion_count_a</th>\n",
       "      <th>gestation_a</th>\n",
       "      <th>prior_transplant_a</th>\n",
       "      <th>c_pra_a</th>\n",
       "      <th>hla_a1_a</th>\n",
       "      <th>hla_a2_a</th>\n",
       "      <th>hla_b1_a</th>\n",
       "      <th>hla_b2_a</th>\n",
       "      <th>hla_dr1_a</th>\n",
       "      <th>hla_dr2_a</th>\n",
       "      <th>anti_hbc_a</th>\n",
       "      <th>anti_hcv_a</th>\n",
       "      <th>hbs_ag_a</th>\n",
       "      <th>days_waiting_a</th>\n",
       "      <th>date_transplanted_a</th>\n",
       "      <th>a_00_homozygous_a</th>\n",
       "      <th>sex_M_a</th>\n",
       "      <th>b_00_homozygous_a</th>\n",
       "      <th>blood_type_AB_a</th>\n",
       "      <th>blood_type_B_a</th>\n",
       "      <th>blood_type_O_a</th>\n",
       "      <th>underlying_disease_glomerulonephritis_a</th>\n",
       "      <th>underlying_disease_hypertension_a</th>\n",
       "      <th>underlying_disease_other_a</th>\n",
       "      <th>underlying_disease_pyelonephritis_a</th>\n",
       "      <th>dr_00_homozygous_a</th>\n",
       "      <th>race_Branca_a</th>\n",
       "      <th>race_Negra_a</th>\n",
       "      <th>race_Parda_a</th>\n",
       "      <th>race_a</th>\n",
       "      <th>sex_a</th>\n",
       "      <th>date_registered_b</th>\n",
       "      <th>age_registered_b</th>\n",
       "      <th>dialysis_session_count_b</th>\n",
       "      <th>diabetes_b</th>\n",
       "      <th>chagas_b</th>\n",
       "      <th>transfusion_count_b</th>\n",
       "      <th>gestation_b</th>\n",
       "      <th>prior_transplant_b</th>\n",
       "      <th>c_pra_b</th>\n",
       "      <th>hla_a1_b</th>\n",
       "      <th>hla_a2_b</th>\n",
       "      <th>hla_b1_b</th>\n",
       "      <th>hla_b2_b</th>\n",
       "      <th>hla_dr1_b</th>\n",
       "      <th>hla_dr2_b</th>\n",
       "      <th>anti_hbc_b</th>\n",
       "      <th>anti_hcv_b</th>\n",
       "      <th>hbs_ag_b</th>\n",
       "      <th>days_waiting_b</th>\n",
       "      <th>date_transplanted_b</th>\n",
       "      <th>a_00_homozygous_b</th>\n",
       "      <th>sex_M_b</th>\n",
       "      <th>b_00_homozygous_b</th>\n",
       "      <th>blood_type_AB_b</th>\n",
       "      <th>blood_type_B_b</th>\n",
       "      <th>blood_type_O_b</th>\n",
       "      <th>underlying_disease_glomerulonephritis_b</th>\n",
       "      <th>underlying_disease_hypertension_b</th>\n",
       "      <th>underlying_disease_other_b</th>\n",
       "      <th>underlying_disease_pyelonephritis_b</th>\n",
       "      <th>dr_00_homozygous_b</th>\n",
       "      <th>race_Branca_b</th>\n",
       "      <th>race_Negra_b</th>\n",
       "      <th>race_Parda_b</th>\n",
       "      <th>race_b</th>\n",
       "      <th>sex_b</th>\n",
       "      <th>transplanted_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13629.0</td>\n",
       "      <td>59</td>\n",
       "      <td>28.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>700</td>\n",
       "      <td>2009-03-26</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Branca</td>\n",
       "      <td>M</td>\n",
       "      <td>13371.0</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1332</td>\n",
       "      <td>2010-04-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14463.0</td>\n",
       "      <td>58</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>847</td>\n",
       "      <td>2011-12-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Branca</td>\n",
       "      <td>M</td>\n",
       "      <td>14194.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1198</td>\n",
       "      <td>2012-02-22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Negra</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15614.0</td>\n",
       "      <td>42</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Branca</td>\n",
       "      <td>M</td>\n",
       "      <td>15562.0</td>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13063.0</td>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2402</td>\n",
       "      <td>2012-05-05</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Branca</td>\n",
       "      <td>M</td>\n",
       "      <td>12951.0</td>\n",
       "      <td>57</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>668</td>\n",
       "      <td>2007-04-16</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Parda</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11248.0</td>\n",
       "      <td>60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1273</td>\n",
       "      <td>2004-04-13</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Parda</td>\n",
       "      <td>M</td>\n",
       "      <td>11107.0</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>781</td>\n",
       "      <td>2002-07-20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Parda</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_registered_a  age_registered_a  ...  sex_b  transplanted_first\n",
       "0            13629.0                59  ...      F                True\n",
       "1            14463.0                58  ...      M                True\n",
       "2            15614.0                42  ...      F               False\n",
       "3            13063.0                41  ...      M               False\n",
       "4            11248.0                60  ...      M               False\n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_pairs(people: pd.DataFrame, n) -> pd.DataFrame:\n",
    "    pairs = set()\n",
    "    while len(pairs) < n:\n",
    "        a = random.randint(1, people.shape[0] - 1)\n",
    "        b = random.randint(max(0, a - 1000), a-1)\n",
    "        pairs.add((a, b))\n",
    "    a = [i for (i, _) in pairs]\n",
    "    b = [i for (_, i) in pairs]\n",
    "\n",
    "    df_a = people.iloc[a]\n",
    "    df_a.columns = df_a.columns + '_a'\n",
    "    df_b = people.iloc[b]\n",
    "    df_b.columns = df_b.columns + '_b'\n",
    "\n",
    "    df_a.index = df_b.index = range(len(pairs))\n",
    "\n",
    "    df_pairs = pd.concat((df_a, df_b), axis=1)\n",
    "    df_pairs['transplanted_first'] = \\\n",
    "        df_pairs['date_transplanted_a'] < df_pairs['date_transplanted_b']\n",
    "    return df_pairs\n",
    "\n",
    "\n",
    "df_pairs = sample_pairs(df_people_train, 200000)\n",
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_registered_a</th>\n",
       "      <th>dialysis_session_count_a</th>\n",
       "      <th>diabetes_a</th>\n",
       "      <th>chagas_a</th>\n",
       "      <th>transfusion_count_a</th>\n",
       "      <th>gestation_a</th>\n",
       "      <th>prior_transplant_a</th>\n",
       "      <th>c_pra_a</th>\n",
       "      <th>hla_a1_a</th>\n",
       "      <th>hla_a2_a</th>\n",
       "      <th>hla_b1_a</th>\n",
       "      <th>hla_b2_a</th>\n",
       "      <th>hla_dr1_a</th>\n",
       "      <th>hla_dr2_a</th>\n",
       "      <th>anti_hbc_a</th>\n",
       "      <th>anti_hcv_a</th>\n",
       "      <th>hbs_ag_a</th>\n",
       "      <th>days_waiting_a</th>\n",
       "      <th>a_00_homozygous_a</th>\n",
       "      <th>b_00_homozygous_a</th>\n",
       "      <th>blood_type_AB_a</th>\n",
       "      <th>blood_type_B_a</th>\n",
       "      <th>blood_type_O_a</th>\n",
       "      <th>underlying_disease_glomerulonephritis_a</th>\n",
       "      <th>underlying_disease_hypertension_a</th>\n",
       "      <th>underlying_disease_other_a</th>\n",
       "      <th>underlying_disease_pyelonephritis_a</th>\n",
       "      <th>dr_00_homozygous_a</th>\n",
       "      <th>race_a</th>\n",
       "      <th>sex_a</th>\n",
       "      <th>date_registered_a</th>\n",
       "      <th>date_transplanted_a</th>\n",
       "      <th>age_registered_b</th>\n",
       "      <th>dialysis_session_count_b</th>\n",
       "      <th>diabetes_b</th>\n",
       "      <th>chagas_b</th>\n",
       "      <th>transfusion_count_b</th>\n",
       "      <th>gestation_b</th>\n",
       "      <th>prior_transplant_b</th>\n",
       "      <th>c_pra_b</th>\n",
       "      <th>hla_a1_b</th>\n",
       "      <th>hla_a2_b</th>\n",
       "      <th>hla_b1_b</th>\n",
       "      <th>hla_b2_b</th>\n",
       "      <th>hla_dr1_b</th>\n",
       "      <th>hla_dr2_b</th>\n",
       "      <th>anti_hbc_b</th>\n",
       "      <th>anti_hcv_b</th>\n",
       "      <th>hbs_ag_b</th>\n",
       "      <th>days_waiting_b</th>\n",
       "      <th>a_00_homozygous_b</th>\n",
       "      <th>b_00_homozygous_b</th>\n",
       "      <th>blood_type_AB_b</th>\n",
       "      <th>blood_type_B_b</th>\n",
       "      <th>blood_type_O_b</th>\n",
       "      <th>underlying_disease_glomerulonephritis_b</th>\n",
       "      <th>underlying_disease_hypertension_b</th>\n",
       "      <th>underlying_disease_other_b</th>\n",
       "      <th>underlying_disease_pyelonephritis_b</th>\n",
       "      <th>dr_00_homozygous_b</th>\n",
       "      <th>race_b</th>\n",
       "      <th>sex_b</th>\n",
       "      <th>date_registered_b</th>\n",
       "      <th>date_transplanted_b</th>\n",
       "      <th>transplanted_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.707247</td>\n",
       "      <td>-5.583849</td>\n",
       "      <td>0.222175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669011</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>-0.101278</td>\n",
       "      <td>14.311298</td>\n",
       "      <td>-7.365861</td>\n",
       "      <td>43.349373</td>\n",
       "      <td>-15.865027</td>\n",
       "      <td>-23.963252</td>\n",
       "      <td>6.485917</td>\n",
       "      <td>4.752868</td>\n",
       "      <td>-0.021678</td>\n",
       "      <td>-0.009784</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>65.810147</td>\n",
       "      <td>-0.095291</td>\n",
       "      <td>-0.050848</td>\n",
       "      <td>0.962516</td>\n",
       "      <td>-0.115482</td>\n",
       "      <td>-0.407581</td>\n",
       "      <td>-0.192500</td>\n",
       "      <td>-0.232678</td>\n",
       "      <td>0.672556</td>\n",
       "      <td>-0.025203</td>\n",
       "      <td>-0.040625</td>\n",
       "      <td>Branca</td>\n",
       "      <td>M</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>2010-06-21</td>\n",
       "      <td>2.958478</td>\n",
       "      <td>74.233019</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.337311</td>\n",
       "      <td>-0.492080</td>\n",
       "      <td>0.911376</td>\n",
       "      <td>-12.042648</td>\n",
       "      <td>24.826941</td>\n",
       "      <td>16.889024</td>\n",
       "      <td>31.198595</td>\n",
       "      <td>22.216672</td>\n",
       "      <td>3.379731</td>\n",
       "      <td>2.870809</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>928.832965</td>\n",
       "      <td>-0.076394</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>-0.030686</td>\n",
       "      <td>-0.085568</td>\n",
       "      <td>0.673262</td>\n",
       "      <td>-0.188164</td>\n",
       "      <td>0.861001</td>\n",
       "      <td>-0.319285</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>-0.037583</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>13700.0</td>\n",
       "      <td>2012-04-20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.341388</td>\n",
       "      <td>24.784599</td>\n",
       "      <td>0.811616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.938269</td>\n",
       "      <td>0.224507</td>\n",
       "      <td>-0.021659</td>\n",
       "      <td>3.041404</td>\n",
       "      <td>26.801983</td>\n",
       "      <td>25.612869</td>\n",
       "      <td>4.760950</td>\n",
       "      <td>38.749844</td>\n",
       "      <td>-0.968138</td>\n",
       "      <td>7.636890</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>172.349716</td>\n",
       "      <td>-0.036375</td>\n",
       "      <td>-0.013385</td>\n",
       "      <td>-0.032853</td>\n",
       "      <td>-0.074677</td>\n",
       "      <td>0.877186</td>\n",
       "      <td>-0.007280</td>\n",
       "      <td>-0.154136</td>\n",
       "      <td>0.976074</td>\n",
       "      <td>-0.003042</td>\n",
       "      <td>-0.011853</td>\n",
       "      <td>Negra</td>\n",
       "      <td>M</td>\n",
       "      <td>16092.0</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>23.060822</td>\n",
       "      <td>-3.233740</td>\n",
       "      <td>0.487308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.764348</td>\n",
       "      <td>0.141106</td>\n",
       "      <td>-0.055485</td>\n",
       "      <td>0.352956</td>\n",
       "      <td>-5.351047</td>\n",
       "      <td>-17.223325</td>\n",
       "      <td>-2.041441</td>\n",
       "      <td>24.516540</td>\n",
       "      <td>0.283020</td>\n",
       "      <td>3.870974</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>-242.018135</td>\n",
       "      <td>-0.071885</td>\n",
       "      <td>-0.031859</td>\n",
       "      <td>-0.026057</td>\n",
       "      <td>0.903514</td>\n",
       "      <td>-0.264582</td>\n",
       "      <td>-0.124324</td>\n",
       "      <td>0.795105</td>\n",
       "      <td>-0.175883</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>-0.025838</td>\n",
       "      <td>Parda</td>\n",
       "      <td>M</td>\n",
       "      <td>15792.0</td>\n",
       "      <td>2014-02-23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.958478</td>\n",
       "      <td>-9.766981</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.337311</td>\n",
       "      <td>-0.492080</td>\n",
       "      <td>-0.088624</td>\n",
       "      <td>-2.042648</td>\n",
       "      <td>-3.173059</td>\n",
       "      <td>48.889024</td>\n",
       "      <td>15.198595</td>\n",
       "      <td>9.216672</td>\n",
       "      <td>-3.620269</td>\n",
       "      <td>4.870809</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.009722</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>246.832965</td>\n",
       "      <td>-0.076394</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>-0.030686</td>\n",
       "      <td>-0.085568</td>\n",
       "      <td>-0.326738</td>\n",
       "      <td>-0.188164</td>\n",
       "      <td>-0.138999</td>\n",
       "      <td>0.680715</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>-0.037583</td>\n",
       "      <td>Branca</td>\n",
       "      <td>F</td>\n",
       "      <td>12277.0</td>\n",
       "      <td>2006-07-16</td>\n",
       "      <td>3.726548</td>\n",
       "      <td>14.583127</td>\n",
       "      <td>0.590629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.241975</td>\n",
       "      <td>-0.367705</td>\n",
       "      <td>-0.042831</td>\n",
       "      <td>-8.000991</td>\n",
       "      <td>-2.158245</td>\n",
       "      <td>15.316326</td>\n",
       "      <td>32.022180</td>\n",
       "      <td>-3.303535</td>\n",
       "      <td>6.176834</td>\n",
       "      <td>5.988916</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>-401.995317</td>\n",
       "      <td>-0.052987</td>\n",
       "      <td>-0.021458</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.066572</td>\n",
       "      <td>-0.183739</td>\n",
       "      <td>0.880012</td>\n",
       "      <td>-0.111216</td>\n",
       "      <td>-0.167724</td>\n",
       "      <td>-0.010443</td>\n",
       "      <td>-0.022797</td>\n",
       "      <td>Parda</td>\n",
       "      <td>F</td>\n",
       "      <td>11423.0</td>\n",
       "      <td>2001-06-15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.939178</td>\n",
       "      <td>5.766260</td>\n",
       "      <td>0.487308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.235652</td>\n",
       "      <td>0.141106</td>\n",
       "      <td>-0.055485</td>\n",
       "      <td>0.352956</td>\n",
       "      <td>-3.351047</td>\n",
       "      <td>10.776675</td>\n",
       "      <td>-3.041441</td>\n",
       "      <td>8.516540</td>\n",
       "      <td>7.283020</td>\n",
       "      <td>5.870974</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>-204.018135</td>\n",
       "      <td>-0.071885</td>\n",
       "      <td>-0.031859</td>\n",
       "      <td>0.973943</td>\n",
       "      <td>-0.096486</td>\n",
       "      <td>-0.264582</td>\n",
       "      <td>-0.124324</td>\n",
       "      <td>-0.204895</td>\n",
       "      <td>0.824117</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>-0.025838</td>\n",
       "      <td>Parda</td>\n",
       "      <td>M</td>\n",
       "      <td>14970.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>39.658612</td>\n",
       "      <td>10.784599</td>\n",
       "      <td>0.811616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.061731</td>\n",
       "      <td>0.224507</td>\n",
       "      <td>0.978341</td>\n",
       "      <td>3.041404</td>\n",
       "      <td>23.801983</td>\n",
       "      <td>-10.387131</td>\n",
       "      <td>4.760950</td>\n",
       "      <td>25.749844</td>\n",
       "      <td>9.031862</td>\n",
       "      <td>8.636890</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>880.349716</td>\n",
       "      <td>0.963625</td>\n",
       "      <td>-0.013385</td>\n",
       "      <td>-0.032853</td>\n",
       "      <td>-0.074677</td>\n",
       "      <td>0.877186</td>\n",
       "      <td>-0.007280</td>\n",
       "      <td>-0.154136</td>\n",
       "      <td>0.976074</td>\n",
       "      <td>-0.003042</td>\n",
       "      <td>-0.011853</td>\n",
       "      <td>Negra</td>\n",
       "      <td>M</td>\n",
       "      <td>14809.0</td>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.726548</td>\n",
       "      <td>-1.416873</td>\n",
       "      <td>0.590629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.241975</td>\n",
       "      <td>0.632295</td>\n",
       "      <td>-0.042831</td>\n",
       "      <td>7.999009</td>\n",
       "      <td>-2.158245</td>\n",
       "      <td>10.316326</td>\n",
       "      <td>3.022180</td>\n",
       "      <td>21.696465</td>\n",
       "      <td>1.176834</td>\n",
       "      <td>7.988916</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>667.004683</td>\n",
       "      <td>-0.052987</td>\n",
       "      <td>-0.021458</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.066572</td>\n",
       "      <td>-0.183739</td>\n",
       "      <td>-0.119988</td>\n",
       "      <td>-0.111216</td>\n",
       "      <td>0.832276</td>\n",
       "      <td>-0.010443</td>\n",
       "      <td>-0.022797</td>\n",
       "      <td>Parda</td>\n",
       "      <td>F</td>\n",
       "      <td>15580.0</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>16.292753</td>\n",
       "      <td>-0.583849</td>\n",
       "      <td>-0.777825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.330989</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>-0.101278</td>\n",
       "      <td>-3.688702</td>\n",
       "      <td>-5.365861</td>\n",
       "      <td>5.349373</td>\n",
       "      <td>-16.865027</td>\n",
       "      <td>-11.963252</td>\n",
       "      <td>5.485917</td>\n",
       "      <td>4.752868</td>\n",
       "      <td>-0.021678</td>\n",
       "      <td>-0.009784</td>\n",
       "      <td>-0.005444</td>\n",
       "      <td>-503.189853</td>\n",
       "      <td>-0.095291</td>\n",
       "      <td>-0.050848</td>\n",
       "      <td>0.962516</td>\n",
       "      <td>-0.115482</td>\n",
       "      <td>-0.407581</td>\n",
       "      <td>-0.192500</td>\n",
       "      <td>-0.232678</td>\n",
       "      <td>-0.327444</td>\n",
       "      <td>-0.025203</td>\n",
       "      <td>-0.040625</td>\n",
       "      <td>Branca</td>\n",
       "      <td>M</td>\n",
       "      <td>15398.0</td>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_registered_a  ...  transplanted_first\n",
       "0         -4.707247  ...                True\n",
       "1        -13.341388  ...               False\n",
       "2         16.958478  ...               False\n",
       "3        -17.939178  ...                True\n",
       "4         24.726548  ...               False\n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs_uncorrelated = sample_pairs(df_people_train_uncorrelated, 200000)\n",
    "df_pairs_uncorrelated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_meta_split(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    target = 'transplanted_first'\n",
    "    _meta = ['days_waiting_a', 'days_waiting_b', 'date_transplanted_a', 'date_transplanted_b', 'sex_a', 'sex_b', 'race_a', 'race_b']\n",
    "    return df.drop(columns=[target, *_meta]), df[target], df[_meta]\n",
    "\n",
    "\n",
    "X, y, meta = X_y_meta_split(df_pairs)\n",
    "Xu, yu, metau = X_y_meta_split(df_pairs_uncorrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'rpy2': FairAdapt will be unavailable. To install, run:\n",
      "pip install 'aif360[FairAdapt]'\n",
      "WARNING:root:No module named 'torch': LearnedFairRepresentations will be unavailable. To install, run:\n",
      "pip install 'aif360[LFR]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.sklearn.preprocessing import Reweighing\n",
    "\n",
    "protected_columns = ['sex_a', 'sex_b', 'race_a', 'race_b']\n",
    "\n",
    "X_p = pd.concat([X, meta[protected_columns]], axis=1)\n",
    "Xu_p = pd.concat([Xu, metau[protected_columns]], axis=1)\n",
    "\n",
    "def reweigh_pairs(X: pd.DataFrame, y: pd.DataFrame) -> [float]:\n",
    "    return Reweighing(protected_columns).fit_transform(X.set_index(protected_columns), y)[1]\n",
    "\n",
    "Wx = reweigh_pairs(X_p,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def make_classifier():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_features='log2',\n",
    "        random_state=1729,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "def train_classifier(X, y):\n",
    "    classifier = make_classifier()\n",
    "    classifier.fit(X, y)\n",
    "    return classifier\n",
    "\n",
    "classifier = train_classifier(X, y)\n",
    "df_pairs_test = sample_pairs(df_people_test, 200000)\n",
    "X_test, y_test, meta_test = X_y_meta_split(df_pairs_test)\n",
    "y_train_pred = classifier.predict_proba(X)[:, 1]\n",
    "y_pred = classifier.predict_proba(X_test)[:, 1]\n",
    "del classifier\n",
    "\n",
    "classifier = train_classifier(Xu, yu)\n",
    "df_pairs_test_uncorrelated = sample_pairs(df_people_test_uncorrelated, 200000)\n",
    "Xu_test, yu_test, metau_test = X_y_meta_split(df_pairs_test_uncorrelated)\n",
    "yu_pred = classifier.predict_proba(Xu_test)[:, 1]\n",
    "del classifier\n",
    "\n",
    "classifier = make_classifier()\n",
    "classifier.fit(X,y,Wx)\n",
    "yw_pred = classifier.predict_proba(X_test)[:, 1]\n",
    "del classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline - acurácia: 0.60174, ROC AUC:0.5388104323753523\n",
      "correlation remover - acurácia: 0.61487, ROC AUC:0.5292715489785901\n",
      "reweighted - acurácia: 0.60394, ROC AUC:0.5401519067530287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(f'baseline - acurácia: {accuracy_score(y_test, y_pred > 0.5)}, ROC AUC:{roc_auc_score(y_test, y_pred > 0.5)}')\n",
    "print(f'correlation remover - acurácia: {accuracy_score(yu_test, yu_pred > 0.5)}, ROC AUC:{roc_auc_score(yu_test, yu_pred > 0.5)}')\n",
    "print(f'reweighted - acurácia: {accuracy_score(y_test, yw_pred > 0.5)}, ROC AUC:{roc_auc_score(y_test, yw_pred > 0.5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExponentiatedGradientReduction(constraints=&lt;fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7fc36d87ee50&gt;,\n",
       "                               eps=0.1,\n",
       "                               estimator=RandomForestClassifier(max_features=&#x27;log2&#x27;,\n",
       "                                                                n_estimators=200,\n",
       "                                                                n_jobs=-1,\n",
       "                                                                random_state=1729),\n",
       "                               prot_attr=[&#x27;sex_a&#x27;, &#x27;sex_b&#x27;, &#x27;race_a&#x27;, &#x27;race_b&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExponentiatedGradientReduction</label><div class=\"sk-toggleable__content\"><pre>ExponentiatedGradientReduction(constraints=&lt;fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7fc36d87ee50&gt;,\n",
       "                               eps=0.1,\n",
       "                               estimator=RandomForestClassifier(max_features=&#x27;log2&#x27;,\n",
       "                                                                n_estimators=200,\n",
       "                                                                n_jobs=-1,\n",
       "                                                                random_state=1729),\n",
       "                               prot_attr=[&#x27;sex_a&#x27;, &#x27;sex_b&#x27;, &#x27;race_a&#x27;, &#x27;race_b&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;log2&#x27;, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=1729)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;log2&#x27;, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=1729)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExponentiatedGradientReduction(constraints=<fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7fc36d87ee50>,\n",
       "                               eps=0.1,\n",
       "                               estimator=RandomForestClassifier(max_features='log2',\n",
       "                                                                n_estimators=200,\n",
       "                                                                n_jobs=-1,\n",
       "                                                                random_state=1729),\n",
       "                               prot_attr=['sex_a', 'sex_b', 'race_a', 'race_b'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.sklearn.inprocessing import ExponentiatedGradientReduction\n",
    "from fairlearn.reductions import EqualizedOdds\n",
    "\n",
    "inpro = ExponentiatedGradientReduction(protected_columns, make_classifier(), EqualizedOdds(), eps=0.1)\n",
    "inpro.fit(X_p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_pred = inpro.predict_proba(X_p)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponentiated gradient - acurácia: 0.52395, ROC AUC:0.5010105272121975\n"
     ]
    }
   ],
   "source": [
    "print(f'exponentiated gradient - acurácia: {accuracy_score(y_test, yf_pred > 0.5)}, ROC AUC:{roc_auc_score(y_test, yf_pred > 0.5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.pos_basis[i] = 0 + zero_vec\n",
      "/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/.venv/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.neg_basis[i] = 0 + zero_vec\n",
      "WARNING:fairlearn.reductions._grid_search._grid_generator:The grid has 126 dimensions. It is not recommended to use more than 4, otherwise a prohibitively large grid size is required to explore the space thoroughly. For such cases consider using ExponentiatedGradient from the fairlearn.reductions module.\n",
      "WARNING:fairlearn.reductions._grid_search._grid_generator:Generating a grid with 10 grid points. It is recommended to use at least 85070591730234615865843651857942052864 grid points. Please consider increasing grid_size.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchReduction(constraints=&lt;fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7fc36d277c90&gt;,\n",
       "                    estimator=RandomForestClassifier(max_features=&#x27;log2&#x27;,\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=1729),\n",
       "                    prot_attr=[&#x27;sex_a&#x27;, &#x27;sex_b&#x27;, &#x27;race_a&#x27;, &#x27;race_b&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchReduction</label><div class=\"sk-toggleable__content\"><pre>GridSearchReduction(constraints=&lt;fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7fc36d277c90&gt;,\n",
       "                    estimator=RandomForestClassifier(max_features=&#x27;log2&#x27;,\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=1729),\n",
       "                    prot_attr=[&#x27;sex_a&#x27;, &#x27;sex_b&#x27;, &#x27;race_a&#x27;, &#x27;race_b&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;log2&#x27;, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=1729)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;log2&#x27;, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=1729)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchReduction(constraints=<fairlearn.reductions._moments.utility_parity.EqualizedOdds object at 0x7fc36d277c90>,\n",
       "                    estimator=RandomForestClassifier(max_features='log2',\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=1729),\n",
       "                    prot_attr=['sex_a', 'sex_b', 'race_a', 'race_b'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.sklearn.inprocessing import GridSearchReduction\n",
    "inpro2 = GridSearchReduction(protected_columns, make_classifier(), EqualizedOdds())\n",
    "inpro2.fit(X_p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf2_pred = inpro2.predict_proba(X_p)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid search - acurácia: 0.626045, ROC AUC:0.49978128814663847\n"
     ]
    }
   ],
   "source": [
    "print(f'grid search - acurácia: {accuracy_score(y_test, yf2_pred > 0.5)}, ROC AUC:{roc_auc_score(y_test, yf2_pred > 0.5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yf_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/fairness.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/fairness.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m metric_frame(y_test, y_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, df_pairs_test[\u001b[39m'\u001b[39m\u001b[39msex_a\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/fairness.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m metric_frame(yu_test, yu_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, df_pairs_test_uncorrelated[\u001b[39m'\u001b[39m\u001b[39msex_a\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/fairness.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m metric_frame(y_test, yf_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, df_pairs_test_uncorrelated[\u001b[39m'\u001b[39m\u001b[39msex_a\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/fairness.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m metric_frame(y_test, yf2_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, df_pairs_test_uncorrelated[\u001b[39m'\u001b[39m\u001b[39msex_a\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/guigb/workspace/unicamp/ia2/mo810-kidney-waitlist/fairness.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m metric_frame(y_test, y_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, df_pairs_test[\u001b[39m'\u001b[39m\u001b[39mrace_a\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yf_pred' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9UAAAHiCAYAAADmqu8jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcOUlEQVR4nO3deViU9f7/8deAMKgILiwqkSSnXNK0MPftFIlLdiz3OolYWiltfLMyU1xSSsss0yjLrI4madqmaUp6WtQsbbO0RUVND4iaQC4g8Pn90Y/JkQGZ22UAn4/rmuuSez733O97uH0zr7k3mzHGCAAAAAAAuM3L0wUAAAAAAFBREaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQCo5Gw2myZMmODWPEOHDlVERMR5qQfAhfHVV1+pffv2ql69umw2m7799tsyzzt//nzZbDalpaWdt/rKg7S0NNlsNs2fP79M4630U1R+hGoAAACgkjl58qT69++vw4cP69lnn9Wbb76pBg0aeLqsCmHFihWVLjgfO3ZMEyZM0Lp16zxdSqVUxdMFAACA8+v48eOqUsW9P/lz585VYWHheaoIwPm2Y8cO7d69W3PnztWdd97p6XLKrQYNGuj48ePy8fFxTFuxYoVmz57tMlhb6aflwbFjxzRx4kRJUteuXT1bTCXEnmpcFI4ePerpEgDgjAoLC3XixIlz/rp+fn5ufwj08fGR3W4/57UAuDAOHDggSapZs6ZnCynnbDab/Pz85O3tXabxVvrp+ZCfn6+8vDxPl4H/j1ANS3bv3q2RI0eqUaNGqlq1qurUqaP+/fu7PO/myJEjevDBBxURESG73a5LLrlEQ4YM0cGDBx1jTpw4oQkTJuiKK66Qn5+f6tWrp1tuuUU7duyQJK1bt042m63YISuuzoMZOnSo/P39tWPHDvXs2VM1atTQbbfdJkn67LPP1L9/f1166aWy2+0KDw/Xgw8+qOPHjxere/v27RowYICCg4NVtWpVNWrUSGPHjpUkrV27VjabTcuWLSs238KFC2Wz2bRhwwZ331YAlcSECRNks9kcfSQgIEB16tTR/fff7xSabTab4uPjtWDBAl155ZWy2+1auXKlJGnfvn0aNmyYQkNDZbfbdeWVV2revHnFlnWm/lm0nFP3uOTk5OiBBx5w9OWQkBDdcMMN2rJli2OMq3Oqjx49qv/7v/9TeHi47Ha7GjVqpKefflrGGKdxRev17rvvqlmzZo76i9YNwPk1dOhQdenSRZLUv39/2Ww2x97J77//XkOHDlXDhg3l5+enunXratiwYTp06NAZX/frr79WTEyMgoKCVLVqVV122WUaNmyY05jCwkLNnDlTV155pfz8/BQaGqq77rpLf/zxR5nq9vf3186dOxUTE6Pq1aurfv36mjRpUrE+U9Z+tHr1anXs2FE1a9aUv7+/GjVqpMcee8zx/OmfJYcOHarZs2dL+quXFT2KnNpPlyxZIpvNpv/+97/F1uWll16SzWbT1q1bHdO2b9+ufv36qXbt2vLz81OrVq30/vvvn/F9Karx6aef1syZMxUZGSm73a6ffvpJeXl5Gj9+vKKiohQYGKjq1aurU6dOWrt2rdP8wcHBkqSJEyc61unUvwtWa8NfPP81Cyqkr776SuvXr9egQYN0ySWXKC0tTS+++KK6du2qn376SdWqVZMk/fnnn+rUqZO2bdumYcOG6ZprrtHBgwf1/vvv6/fff1dQUJAKCgp04403KjU1VYMGDdL999+vnJwcrV69Wlu3blVkZKTb9eXn5ysmJkYdO3bU008/7ahn8eLFOnbsmO655x7VqVNHmzZt0qxZs/T7779r8eLFjvm///57derUST4+PhoxYoQiIiK0Y8cOffDBB5oyZYq6du2q8PBwLViwQDfffLPTshcsWKDIyEi1a9fuLN5hAJXBgAEDFBERoaSkJG3cuFHPP/+8/vjjD73xxhuOMZ988onefvttxcfHKygoSBEREcrIyFDbtm0d4TQ4OFgfffSR7rjjDmVnZ+uBBx6QJMv98+6779aSJUsUHx+vpk2b6tChQ/r888+1bds2XXPNNS7nMcbopptu0tq1a3XHHXeoZcuWWrVqlUaPHq19+/bp2WefdRr/+eefa+nSpRo5cqRq1Kih559/Xn379tWePXtUp06dc/MGA3DprrvuUlhYmKZOnar77rtP1157rUJDQyX9FTJ37typuLg41a1bVz/++KNefvll/fjjj9q4caNTgDzVgQMH1K1bNwUHB+vRRx9VzZo1lZaWpqVLlxZb9vz58xUXF6f77rtPu3bt0gsvvKBvvvlGX3zxhdNh1q4UFBSoe/fuatu2raZNm6aVK1cqMTFR+fn5mjRpkqSy96Mff/xRN954o6666ipNmjRJdrtdv/32m7744otS37v9+/dr9erVevPNN0uttVevXvL399fbb7/t+BKjSEpKiq688ko1a9bMUUuHDh0UFhamRx99VNWrV9fbb7+tPn366J133in2edKV1157TSdOnNCIESNkt9tVu3ZtZWdn65VXXtHgwYM1fPhw5eTk6NVXX1VMTIw2bdqkli1bKjg4WC+++KLuuece3XzzzbrlllskSVddddU5q+2iZwALjh07Vmzahg0bjCTzxhtvOKaNHz/eSDJLly4tNr6wsNAYY8y8efOMJDNjxowSx6xdu9ZIMmvXrnV6fteuXUaSee211xzTYmNjjSTz6KOPlqnupKQkY7PZzO7dux3TOnfubGrUqOE07dR6jDFmzJgxxm63myNHjjimHThwwFSpUsUkJiYWWw6Ai0diYqKRZG666San6SNHjjSSzHfffWeMMUaS8fLyMj/++KPTuDvuuMPUq1fPHDx40Gn6oEGDTGBgoKOXlaV/Fi3n1L4UGBhoRo0aVeo6xMbGmgYNGjh+fvfdd40k88QTTziN69evn7HZbOa3335zWp6vr6/TtO+++85IMrNmzSp1uQDOjaLPTosXL3aa7uqz0FtvvWUkmU8//dQx7bXXXjOSzK5du4wxxixbtsxIMl999VWJy/zss8+MJLNgwQKn6StXrnQ5/XRFn+Huvfdex7TCwkLTq1cv4+vrazIzM40xZe9Hzz77rJHkmM8VV58lR40aZUqKSaf308GDB5uQkBCTn5/vmPa///3PeHl5mUmTJjmmXX/99aZ58+bmxIkTTuvWvn17c/nll5fyrvxdY0BAgDlw4IDTc/n5+SY3N9dp2h9//GFCQ0PNsGHDHNMyMzOL1X4uasNfOPwbllStWtXx75MnT+rQoUP6xz/+oZo1azodPvjOO++oRYsWLr/hKvom9J133lFQUJDuvffeEsdYcc8995Ra99GjR3Xw4EG1b99exhh98803kqTMzEx9+umnGjZsmC699NIS6xkyZIhyc3O1ZMkSx7SUlBTl5+fr3//+t+W6AVQeo0aNcvq5qM+tWLHCMa1Lly5q2rSp42djjN555x317t1bxhgdPHjQ8YiJiVFWVpajz1rtnzVr1tSXX36p/fv3l3ldVqxYIW9vb913331O0//v//5Pxhh99NFHTtOjo6Od9pRfddVVCggI0M6dO8u8TADn3qmfhU6cOKGDBw+qbdu2kuT0Ge50Redmf/jhhzp58qTLMYsXL1ZgYKBuuOEGp94VFRUlf39/p0OSSxMfH+/4d9ERO3l5eVqzZo2ksvejoprfe++983bhxYEDB+rAgQNOpyguWbJEhYWFGjhwoCTp8OHD+uSTTzRgwADl5OQ43pdDhw4pJiZGv/76q/bt23fGZfXt29dxGHcRb29v+fr6Svrr0PvDhw8rPz9frVq1KvX3WeRc1XaxI1TDkuPHj2v8+PGO81iCgoIUHBysI0eOKCsryzFux44djsNeSrJjxw41atTonF70oUqVKrrkkkuKTd+zZ4+GDh2q2rVry9/fX8HBwY7DdYrqLvrAd6a6GzdurGuvvVYLFixwTFuwYIHatm2rf/zjH+dqVQBUYJdffrnTz5GRkfLy8nK6/sRll13mNCYzM1NHjhzRyy+/rODgYKdHXFycpL8vQGS1f06bNk1bt25VeHi4WrdurQkTJpwx7O7evVv169dXjRo1nKY3adLE8fypTv9SUpJq1apVpvMqAZw/hw8f1v3336/Q0FBVrVpVwcHBjj506me403Xp0kV9+/bVxIkTFRQUpH/961967bXXlJub6xjz66+/KisrSyEhIcX6159//unoXaXx8vJSw4YNnaZdccUVkuTonWXtRwMHDlSHDh105513KjQ0VIMGDdLbb799TgN29+7dFRgYqJSUFMe0lJQUtWzZ0lH3b7/9JmOMxo0bV+x9SUxMlKQyvTen/70o8vrrr+uqq66Sn5+f6tSpo+DgYC1fvrzU32eRc1XbxY5zqmHJvffeq9dee00PPPCA2rVrp8DAQNlsNg0aNOi8fBNY0h6XgoICl9Ptdru8vLyKjb3hhht0+PBhPfLII2rcuLGqV6+uffv2aejQoZbqHjJkiO6//379/vvvys3N1caNG/XCCy+4/ToALg6uetmpe40kOXrRv//9b8XGxrp8naLz4KwaMGCAOnXqpGXLlunjjz/W9OnT9dRTT2np0qXq0aPHWb12kZKupGtOu4gQgAtrwIABWr9+vUaPHq2WLVvK399fhYWF6t69e6mfhWw2m5YsWaKNGzfqgw8+0KpVqzRs2DA988wz2rhxo+N1QkJCnHY4nOr0vaznW9WqVfXpp59q7dq1Wr58uVauXKmUlBRdd911+vjjj8t8xe/S2O129enTR8uWLdOcOXOUkZGhL774QlOnTnWMKXpfH3roIcXExLh8nbLskDn974Uk/ec//9HQoUPVp08fjR49WiEhIfL29lZSUpLTBStLcq5qu9gRqmHJkiVLFBsbq2eeecYx7cSJEzpy5IjTuMjISKerHroSGRmpL7/8UidPnizx4hW1atWSpGKvf/qekdL88MMP+uWXX/T6669ryJAhjumrV692Glf07eiZ6pakQYMGKSEhQW+99ZbjHodFh/oAwK+//uq0Z+G3335TYWFhsatqnyo4OFg1atRQQUGBoqOjS339svTPktSrV08jR47UyJEjdeDAAV1zzTWaMmVKiaG6QYMGWrNmjXJycpz2Dm3fvt3xPIDy7Y8//lBqaqomTpyo8ePHO6b/+uuvZX6Ntm3bqm3btpoyZYoWLlyo2267TYsWLdKdd96pyMhIrVmzRh06dHAZAMuisLBQO3fudOzllaRffvlFkhy9051+5OXlpeuvv17XX3+9ZsyYoalTp2rs2LFau3ZtiT3W3dMPBw4cqNdff12pqanatm2bjDFOnweLPlv6+Picsa+7a8mSJWrYsKGWLl3qVHfRXuYiJa3T+aztYsLh37DE29u72N6GWbNmFdtz3LdvX3333Xcubz1VNH/fvn118OBBl3t4i8Y0aNBA3t7e+vTTT52enzNnjls1n/qaRf9+7rnnnMYFBwerc+fOmjdvnvbs2eOyniJBQUHq0aOH/vOf/2jBggXq3r27goKCylwTgMqt6LYsRWbNmiVJpe4N9vb2Vt++ffXOO++4/HIvMzPT8e+y9M/TFRQUFDskMCQkRPXr13c6jPN0PXv2VEFBQbFlPfvss7LZbOdsDzeA88fVZyFJmjlz5hnn/eOPP4rN17JlS0ly9I4BAwaooKBAkydPLjZ/fn5+sZ0jJTm1zxhj9MILL8jHx0fXX3+9pLL3o8OHDxd77dNrdqV69eqSiu/MKUl0dLRq166tlJQUpaSkqHXr1k5fqIaEhKhr16566aWX9L///a/Y/Kf2dXe5+p1++eWXxW7tWnQnnNPX6XzWdjFhTzUsufHGG/Xmm28qMDBQTZs21YYNG7RmzZpit0kZPXq0lixZov79+2vYsGGKiorS4cOH9f777ys5OVktWrTQkCFD9MYbbyghIUGbNm1Sp06ddPToUa1Zs0YjR47Uv/71LwUGBqp///6aNWuWbDabIiMj9eGHH7p1jkfjxo0VGRmphx56SPv27VNAQIDeeecdl+f3Pf/88+rYsaOuueYajRgxQpdddpnS0tK0fPlyffvtt05jhwwZon79+kmSyz8iAC5eu3bt0k033aTu3btrw4YN+s9//qNbb71VLVq0KHW+J598UmvXrlWbNm00fPhwNW3aVIcPH9aWLVu0Zs0axwfFsvTP0+Xk5OiSSy5Rv3791KJFC/n7+2vNmjX66quvnI4+Ol3v3r31z3/+U2PHjlVaWppatGihjz/+WO+9954eeOABS7c/BHBhBQQEqHPnzpo2bZpOnjypsLAwffzxx9q1a9cZ53399dc1Z84c3XzzzYqMjFROTo7mzp2rgIAA9ezZU9Jf513fddddSkpK0rfffqtu3brJx8dHv/76qxYvXqznnnvO8ZmpJH5+flq5cqViY2PVpk0bffTRR1q+fLkee+wxx+HjZe1HkyZN0qeffqpevXqpQYMGOnDggObMmaNLLrlEHTt2LLGGqKgoSdJ9992nmJgYeXt7a9CgQSWO9/Hx0S233KJFixbp6NGjevrpp4uNmT17tjp27KjmzZtr+PDhatiwoTIyMrRhwwb9/vvv+u6770r/BZTgxhtv1NKlS3XzzTerV69e2rVrl5KTk9W0aVP9+eefjnFVq1ZV06ZNlZKSoiuuuEK1a9dWs2bN1KxZs/NW20Xlwl5sHJXFH3/8YeLi4kxQUJDx9/c3MTExZvv27aZBgwYmNjbWaeyhQ4dMfHy8CQsLM76+vuaSSy4xsbGxTreKOXbsmBk7dqy57LLLjI+Pj6lbt67p16+f2bFjh2NMZmam6du3r6lWrZqpVauWueuuu8zWrVtd3lKrevXqLuv+6aefTHR0tPH39zdBQUFm+PDhjtu8nPoaxhizdetWc/PNN5uaNWsaPz8/06hRIzNu3Lhir5mbm2tq1aplAgMDzfHjx91/MwFUOkW31Prpp59Mv379TI0aNUytWrVMfHy8U5+QVOKtrTIyMsyoUaNMeHi4oy9ef/315uWXX3YaV5b+qVNuo5Kbm2tGjx5tWrRoYWrUqGGqV69uWrRoYebMmeP0uqffUssYY3JycsyDDz5o6tevb3x8fMzll19upk+f7nT7rtLWy9XfCADnR0m31Pr9998dn28CAwNN//79zf79+4vdbun0W2pt2bLFDB482Fx66aXGbrebkJAQc+ONN5qvv/662LJffvllExUVZapWrWpq1Khhmjdvbh5++GGzf//+Umsu+gy3Y8cO061bN1OtWjUTGhpqEhMTTUFBgdPYsvSj1NRU869//cvUr1/f+Pr6mvr165vBgwebX375xTHG1S218vPzzb333muCg4ONzWZzur3W6e9TkdWrVxtJxmazmb1797pcvx07dpghQ4aYunXrGh8fHxMWFmZuvPFGs2TJklLfl6Iap0+fXuy5wsJCM3XqVNOgQQNjt9vN1VdfbT788EOXPXz9+vUmKirK+Pr6FlsPq7XhLzZjuGIIcDby8/NVv3599e7dW6+++qqnywFQDkyYMEETJ05UZmYmp4QAQBkNHTpUS5YscdrDClQEnFMNnKV3331XmZmZThc/AwAAAHBx4JxqwKIvv/xS33//vSZPnqyrr77acb9rAAAAABcP9lQDFr344ou65557FBISojfeeMPT5QAAAADwAM6pBgAAAADAIvZUAwAAAABgEaEaAAAAAACLKsSFygoLC7V//37VqFFDNpvN0+UAqGCMMcrJyVH9+vXl5VW5vkukPwI4G/RHAChZWXtkhQjV+/fvV3h4uKfLAFDB7d27V5dccomnyzin6I8AzgX6IwCU7Ew9skKE6ho1akj6a2UCAgI8XA2AiiY7O1vh4eGOXlKZ0B8BnA36IwCUrKw9skKE6qJDdgICAmiKACyrjIf/0R8BnAv0RwAo2Zl6pKWTZ2bPnq2IiAj5+fmpTZs22rRpU6njZ86cqUaNGqlq1aoKDw/Xgw8+qBMnTlhZNAAAAAAA5YbboTolJUUJCQlKTEzUli1b1KJFC8XExOjAgQMuxy9cuFCPPvqoEhMTtW3bNr366qtKSUnRY489dtbFAwAAAADgSW6H6hkzZmj48OGKi4tT06ZNlZycrGrVqmnevHkux69fv14dOnTQrbfeqoiICHXr1k2DBw8+495tAAAAAADKO7dCdV5enjZv3qzo6Oi/X8DLS9HR0dqwYYPLedq3b6/Nmzc7QvTOnTu1YsUK9ezZs8Tl5ObmKjs72+kBAKA/AkBJ6I8APMWtUH3w4EEVFBQoNDTUaXpoaKjS09NdznPrrbdq0qRJ6tixo3x8fBQZGamuXbuWevh3UlKSAgMDHQ9uhwAAf6E/AoBr9EcAnmLpQmXuWLdunaZOnao5c+Zoy5YtWrp0qZYvX67JkyeXOM+YMWOUlZXleOzdu/d8lwkAFQL9EQBcoz8C8BS3bqkVFBQkb29vZWRkOE3PyMhQ3bp1Xc4zbtw43X777brzzjslSc2bN9fRo0c1YsQIjR07Vl5exXO93W6X3W53pzQAuCjQHwHANfojAE9xa0+1r6+voqKilJqa6phWWFio1NRUtWvXzuU8x44dKxacvb29JUnGGHfrBQAAAACg3HBrT7UkJSQkKDY2Vq1atVLr1q01c+ZMHT16VHFxcZKkIUOGKCwsTElJSZKk3r17a8aMGbr66qvVpk0b/fbbbxo3bpx69+7tCNcAAAAAAFREbofqgQMHKjMzU+PHj1d6erpatmyplStXOi5etmfPHqc9048//rhsNpsef/xx7du3T8HBwerdu7emTJly7tYCAAAAAAAPsJkKcAx2dna2AgMDlZWVpYCAAE+XA6CCqcw9pDKvG4DzrzL3kMq8bgAujLL2kfN+9W8AAAAAACorQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGBRFU8XUNFEPLrc0yWUK2lP9vJ0CQAAAADgMeypBgAAAADAIkuhevbs2YqIiJCfn5/atGmjTZs2lTr+yJEjGjVqlOrVqye73a4rrrhCK1assFQwAAAAAADlhduHf6ekpCghIUHJyclq06aNZs6cqZiYGP38888KCQkpNj4vL0833HCDQkJCtGTJEoWFhWn37t2qWbPmuagfAAAAAACPcTtUz5gxQ8OHD1dcXJwkKTk5WcuXL9e8efP06KOPFhs/b948HT58WOvXr5ePj48kKSIi4uyqBsoxzrt3xnn3AAAAqMzcOvw7Ly9PmzdvVnR09N8v4OWl6OhobdiwweU877//vtq1a6dRo0YpNDRUzZo109SpU1VQUFDicnJzc5Wdne30AADQHwGgJPRHAJ7iVqg+ePCgCgoKFBoa6jQ9NDRU6enpLufZuXOnlixZooKCAq1YsULjxo3TM888oyeeeKLE5SQlJSkwMNDxCA8Pd6dMAKi06I8A4Br9EYCnnPerfxcWFiokJEQvv/yyoqKiNHDgQI0dO1bJycklzjNmzBhlZWU5Hnv37j3fZQJAhUB/BADX6I8APMWtc6qDgoLk7e2tjIwMp+kZGRmqW7euy3nq1asnHx8feXt7O6Y1adJE6enpysvLk6+vb7F57Ha77Ha7O6UBwEWB/ggArtEfAXiKW3uqfX19FRUVpdTUVMe0wsJCpaamql27di7n6dChg3777TcVFhY6pv3yyy+qV6+ey0ANAAAAAEBF4fbh3wkJCZo7d65ef/11bdu2Tffcc4+OHj3quBr4kCFDNGbMGMf4e+65R4cPH9b999+vX375RcuXL9fUqVM1atSoc7cWAAAAAAB4gNu31Bo4cKAyMzM1fvx4paenq2XLllq5cqXj4mV79uyRl9ffWT08PFyrVq3Sgw8+qKuuukphYWG6//779cgjj5y7tQAAAAAAwAPcDtWSFB8fr/j4eJfPrVu3rti0du3aaePGjVYWBQAAAABAuXXer/4NAAAAAEBlRagGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsKiKpwsAAFQSEwI9XUH5MyHL0xUAAIDzjD3VAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsMhSqJ49e7YiIiLk5+enNm3aaNOmTWWab9GiRbLZbOrTp4+VxQIAAAAAUK64ffXvlJQUJSQkKDk5WW3atNHMmTMVExOjn3/+WSEhISXOl5aWpoceekidOnU6q4IBAEAFxRXinXF1eACoFNzeUz1jxgwNHz5ccXFxatq0qZKTk1WtWjXNmzevxHkKCgp02223aeLEiWrYsOFZFQwAAAAAQHnhVqjOy8vT5s2bFR0d/fcLeHkpOjpaGzZsKHG+SZMmKSQkRHfccUeZlpObm6vs7GynBwCA/ggAJaE/AvAUt0L1wYMHVVBQoNDQUKfpoaGhSk9PdznP559/rldffVVz584t83KSkpIUGBjoeISHh7tTJgBUWvRHAHCN/gjAU87r1b9zcnJ0++23a+7cuQoKCirzfGPGjFFWVpbjsXfv3vNYJQBUHPRHAHCN/gjAU9y6UFlQUJC8vb2VkZHhND0jI0N169YtNn7Hjh1KS0tT7969HdMKCwv/WnCVKvr5558VGRlZbD673S673e5OaQBwUaA/AoBr9EcAnuLWnmpfX19FRUUpNTXVMa2wsFCpqalq165dsfGNGzfWDz/8oG+//dbxuOmmm/TPf/5T3377LYflAAAAAAAqNLdvqZWQkKDY2Fi1atVKrVu31syZM3X06FHFxcVJkoYMGaKwsDAlJSXJz89PzZo1c5q/Zs2aklRsOgAAAAAAFY3boXrgwIHKzMzU+PHjlZ6erpYtW2rlypWOi5ft2bNHXl7n9VRtAAAAAADKBbdDtSTFx8crPj7e5XPr1q0rdd758+dbWSQAAAAAAOUOu5QBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFlkK1bNnz1ZERIT8/PzUpk0bbdq0qcSxc+fOVadOnVSrVi3VqlVL0dHRpY4HAAAAAKCicDtUp6SkKCEhQYmJidqyZYtatGihmJgYHThwwOX4devWafDgwVq7dq02bNig8PBwdevWTfv27Tvr4gEAAAAA8CS3Q/WMGTM0fPhwxcXFqWnTpkpOTla1atU0b948l+MXLFigkSNHqmXLlmrcuLFeeeUVFRYWKjU19ayLBwAAAADAk9wK1Xl5edq8ebOio6P/fgEvL0VHR2vDhg1leo1jx47p5MmTql27tnuVAgAAAABQzlRxZ/DBgwdVUFCg0NBQp+mhoaHavn17mV7jkUceUf369Z2C+elyc3OVm5vr+Dk7O9udMgGg0qI/AoBr9EcAnnJBr/795JNPatGiRVq2bJn8/PxKHJeUlKTAwEDHIzw8/AJWCQDlF/0RAFyjPwLwFLdCdVBQkLy9vZWRkeE0PSMjQ3Xr1i113qefflpPPvmkPv74Y1111VWljh0zZoyysrIcj71797pTJgBUWvRHAHCN/gjAU9w6/NvX11dRUVFKTU1Vnz59JMlx0bH4+PgS55s2bZqmTJmiVatWqVWrVmdcjt1ul91ud6c0ALgo0B8BwDX6IwBPcStUS1JCQoJiY2PVqlUrtW7dWjNnztTRo0cVFxcnSRoyZIjCwsKUlJQkSXrqqac0fvx4LVy4UBEREUpPT5ck+fv7y9/f/xyuCgAAAABUPM1fb+7pEsqdH2J/8HQJZeZ2qB44cKAyMzM1fvx4paenq2XLllq5cqXj4mV79uyRl9ffR5W/+OKLysvLU79+/ZxeJzExURMmTDi76gEAAAAA8CC3Q7UkxcfHl3i497p165x+TktLs7IIAAAAAADKvQt69W8AAAAAACoTQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGCRpVtqAQAAACib5q8393QJ5c4PsT94ugTgnGFPNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwyFKonj17tiIiIuTn56c2bdpo06ZNpY5fvHixGjduLD8/PzVv3lwrVqywVCwAAAAAAOWJ26E6JSVFCQkJSkxM1JYtW9SiRQvFxMTowIEDLsevX79egwcP1h133KFvvvlGffr0UZ8+fbR169azLh4AAAAAAE9yO1TPmDFDw4cPV1xcnJo2bark5GRVq1ZN8+bNczn+ueeeU/fu3TV69Gg1adJEkydP1jXXXKMXXnjhrIsHAAAAAMCTqrgzOC8vT5s3b9aYMWMc07y8vBQdHa0NGza4nGfDhg1KSEhwmhYTE6N33323xOXk5uYqNzfX8XNWVpYkKTs7251yz4vC3GOeLqFcKQ+/k/KGbcRZedhGimowxni4krNXnvujciv++3vOlYffS3nCNuKsHGwf9McLo+B4gadLKHfKw++lPGEbKa48bCNl7ZFuheqDBw+qoKBAoaGhTtNDQ0O1fft2l/Okp6e7HJ+enl7icpKSkjRx4sRi08PDw90pFxdA4ExPV4DyrjxtIzk5OQoMDPR0GWeF/ljBPFmxtzecZ+Vo+6A/4kILvKdib284/8rTNnKmHulWqL5QxowZ47R3u7CwUFFRUdqyZYtsNpsHKysfsrOzFR4err179yogIMDT5ZQL1157rb766itPl1FusI04M8YoKipK9evX93QpZ43+WDq2fdfokX9jG3FGf7y4sP0XR3/8G9tHcWXtkW6F6qCgIHl7eysjI8NpekZGhurWretynrp167o1XpLsdrvsdnuxaRX9G9RzLSAggA3+//P29ua9cIFt5G++vr7y8qr4dxGkP5YN274zemRxbCN/oz9efNj+/0Z/LI7tw1lZeqRbHdTX11dRUVFKTU11TCssLFRqaqratWvncp527do5jZek1atXlzi+JKNGjXJrPC4ubB84k8q8jVTmdcO5wTaC0lTm7aMyrxvODbYRnElZthGbcfPKFCkpKYqNjdVLL72k1q1ba+bMmXr77be1fft2hYaGasiQIQoLC1NSUpKkv26p1aVLFz355JPq1auXFi1apKlTp2rLli1q1qyZtTW7yGVnZyswMFBZWVl8iwSX2EZwsWLbx5mwjeBixvaP0rB9WOf2OdUDBw5UZmamxo8fr/T0dLVs2VIrV650XIxsz549TrvH27dvr4ULF+rxxx/XY489pssvv1zvvvsugfos2O12JSYmFjvECSjCNoKLFds+zoRtBBcztn+Uhu3DOrf3VAMAAAAAgL9U/KtSAAAAAADgIYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEarLqa+++krt27dX9erVZbPZ9O2335Z53vnz58tmsyktLe281VfZDB06VBEREZ4uA0Al4MkeHBERoaFDh17w5QJAaSZMmCCbzeb4+UL1qrS0NNlsNs2fP98xbejQofL39z/vyy5is9k0YcKEC7Y8eAahuhw6efKk+vfvr8OHD+vZZ5/Vm2++qQYNGni6rApv//79mjBhgltfUFQECxcu1MyZMz1dBoALZP369ZowYYKOHDni6VLOqcq6XgDOjRUrVpTbcFqea8OFUcXTBaC4HTt2aPfu3Zo7d67uvPNOT5dTaezfv18TJ05URESEWrZs6fTc3LlzVVhY6JnCztLChQu1detWPfDAA54uBcAFsH79ek2cOFFDhw5VzZo1nZ77+eef5eVVMb8vL229AFQuVnrVihUrNHv2bLfCa4MGDXT8+HH5+Pi4WaF7Sqvt+PHjqlKFyFXZ8Rsuhw4cOCBJfKi4gM53s3XHsWPHVK1aNU+XAaACstvtni7B4ejRo6pevbqnywBQDp3vXpWfn6/CwkL5+vrKz8/vvC7rTDy9fFwYFfPr7Eps6NCh6tKliySpf//+stls6tq1qyTp+++/19ChQ9WwYUP5+fmpbt26GjZsmA4dOnTG1/36668VExOjoKAgVa1aVZdddpmGDRvmNKawsFAzZ87UlVdeKT8/P4WGhuquu+7SH3/8Uaa6/f39tW/fPvXp00f+/v4KDg7WQw89pIKCAkvLKSws1IQJE1S/fn1Vq1ZN//znP/XTTz8VOw/n8OHDeuihh9S8eXP5+/srICBAPXr00HfffecYs27dOl177bWSpLi4ONlsNqdzbE49p/rkyZOqXbu24uLiiq1ndna2/Pz89NBDDzmm5ebmKjExUf/4xz9kt9sVHh6uhx9+WLm5uWd837p27apmzZpp8+bN6ty5s6pVq6bHHntMkvTee++pV69eql+/vux2uyIjIzV58mSn97Nr165avny5du/e7VinU88NP5vagItJTk6OHnjgAUVERMhutyskJEQ33HCDtmzZ4jTuyy+/VPfu3RUYGKhq1aqpS5cu+uKLL8q0jI8++kidOnVS9erVVaNGDfXq1Us//vhjsXHbt2/XgAEDFBwcrKpVq6pRo0YaO3aspL/OSxw9erQk6bLLLnP8vy86f9vVeYo7d+5U//79Vbt2bVWrVk1t27bV8uXLncasW7dONptNb7/9tqZMmaJLLrlEfn5+uv766/Xbb7+dcd2Kzpf86aefdOutt6pWrVrq2LGjpLL97TrTeknSf/7zH0VFRalq1aqqXbu2Bg0apL17956xNgAX1ueff65rr71Wfn5+ioyM1EsvvVRszOm96uTJk5o4caIuv/xy+fn5qU6dOurYsaNWr14t6a/PabNnz5YkR38oOke76Lzpp59+WjNnzlRkZKTsdrt++uknl+dUF9m5c6diYmJUvXp11a9fX5MmTZIxxvF8UV9ct26d03ynv2ZptRVNO30P9jfffKMePXooICBA/v7+uv7667Vx40anMUXX5/jiiy+UkJCg4OBgVa9eXTfffLMyMzNL/gXAI9hTXc7cddddCgsL09SpU3Xffffp2muvVWhoqCRp9erV2rlzp+Li4lS3bl39+OOPevnll/Xjjz9q48aNTv+BT3XgwAF169ZNwcHBevTRR1WzZk2lpaVp6dKlxZY9f/58xcXF6b777tOuXbv0wgsv6JtvvtEXX3xxxr25BQUFiomJUZs2bfT0009rzZo1euaZZxQZGal77rnH7eWMGTNG06ZNU+/evRUTE6PvvvtOMTExOnHihNNyd+7cqXfffVf9+/fXZZddpoyMDL300kvq0qWLfvrpJ9WvX19NmjTRpEmTNH78eI0YMUKdOnWSJLVv377Yevj4+Ojmm2/W0qVL9dJLL8nX19fx3Lvvvqvc3FwNGjRI0l/B/6abbtLnn3+uESNGqEmTJvrhhx/07LPP6pdfftG7775b6nsmSYcOHVKPHj00aNAg/fvf/3b8vufPny9/f38lJCTI399fn3zyicaPH6/s7GxNnz5dkjR27FhlZWXp999/17PPPitJjotvnIvagIvF3XffrSVLlig+Pl5NmzbVoUOH9Pnnn2vbtm265pprJEmffPKJevTooaioKCUmJsrLy0uvvfaarrvuOn322Wdq3bp1ia//5ptvKjY2VjExMXrqqad07Ngxvfjii+rYsaO++eYbx5dh33//vTp16iQfHx+NGDFCERER2rFjhz744ANNmTJFt9xyi3755Re99dZbevbZZxUUFCRJCg4OdrncjIwMtW/fXseOHdN9992nOnXq6PXXX9dNN92kJUuW6Oabb3Ya/+STT8rLy0sPPfSQsrKyNG3aNN1222368ssvy/Q+9u/fX5dffrmmTp3q+HBalr9dZ1qvKVOmaNy4cRowYIDuvPNOZWZmatasWercubO++eYbjuwCyokffvjB8ZlzwoQJys/PV2JiouOzTUkmTJigpKQk3XnnnWrdurWys7P19ddfa8uWLbrhhht01113af/+/Vq9erXefPNNl6/x2muv6cSJExoxYoTsdrtq165d4ql9BQUF6t69u9q2batp06Zp5cqVSkxMVH5+viZNmuTWOpeltlP9+OOP6tSpkwICAvTwww/Lx8dHL730krp27ar//ve/atOmjdP4e++9V7Vq1VJiYqLS0tI0c+ZMxcfHKyUlxa06cZ4ZlDtr1641kszixYudph87dqzY2LfeestIMp9++qlj2muvvWYkmV27dhljjFm2bJmRZL766qsSl/nZZ58ZSWbBggVO01euXOly+uliY2ONJDNp0iSn6VdffbWJiopyeznp6emmSpUqpk+fPk7jJkyYYCSZ2NhYx7QTJ06YgoICp3G7du0ydrvdqZ6vvvrKSDKvvfaay/obNGjg+HnVqlVGkvnggw+cxvXs2dM0bNjQ8fObb75pvLy8zGeffeY0Ljk52UgyX3zxRbFlnapLly5GkklOTi72nKvf91133WWqVatmTpw44ZjWq1cvp9rPVW3AxSQwMNCMGjWqxOcLCwvN5ZdfbmJiYkxhYaFj+rFjx8xll11mbrjhBse003twTk6OqVmzphk+fLjTa6anp5vAwECn6Z07dzY1atQwu3fvLrb8ItOnT3d6/VM1aNDAqT8+8MADRpJTH8jJyTGXXXaZiYiIcPTOor87TZo0Mbm5uY6xzz33nJFkfvjhhxLfG2OMSUxMNJLM4MGDiz1X1r9dJa1XWlqa8fb2NlOmTHGa/sMPP5gqVaoUmw7Ac/r06WP8/PycethPP/1kvL29zamx4/Re1aJFC9OrV69SX3vUqFHGVXTZtWuXkWQCAgLMgQMHXD536me/os+s9957r2NaYWGh6dWrl/H19TWZmZnGmL/74tq1a8/4miXVZowxkkxiYqLj5z59+hhfX1+zY8cOx7T9+/ebGjVqmM6dOzumFf0tiY6Odvob8OCDDxpvb29z5MgRl8uDZ3D4dwVStWpVx79PnDihgwcPqm3btpJU7BDFUxV9g//hhx/q5MmTLscsXrxYgYGBuuGGG3Tw4EHHIyoqSv7+/lq7dm2Zarz77rudfu7UqZN27tzp9nJSU1OVn5+vkSNHOr3evffeW2yZdrvdcbGLgoICHTp0SP7+/mrUqFGp70tprrvuOgUFBTl9C/jHH39o9erVGjhwoNP6NGnSRI0bN3Zan+uuu06SyvS+2e12l4ean/r7zsnJ0cGDB9WpUycdO3ZM27dvP+PrnovagItFzZo19eWXX2r//v0un//222/166+/6tZbb9WhQ4cc/5+OHj2q66+/Xp9++mmJe0RWr16tI0eOaPDgwU7/F729vdWmTRvH/8XMzEx9+umnGjZsmC699FKn1yjpSKQzWbFihVq3bu04FFv662iWESNGKC0tTT/99JPT+Li4OKejc4qO6jm1j5fm9L8BkvW/XUWWLl2qwsJCDRgwwOn9q1u3ri6//HJ6GVBOFBQUaNWqVerTp49TD2vSpIliYmJKnbdmzZr68ccf9euvv1peft++fUs8aseV+Ph4x79tNpvi4+OVl5enNWvWWK7hTAoKCvTxxx+rT58+atiwoWN6vXr1dOutt+rzzz9Xdna20zwjRoxw+hvQqVMnFRQUaPfu3eetTriPw78rkMOHD2vixIlatGiR42JmRbKyskqcr0uXLurbt68mTpyoZ599Vl27dlWfPn106623Oi4U8euvvyorK0shISEuX+P05bni5+dXrJnVqlXL6Vzpsi6nqFH84x//cHq+du3aqlWrltO0wsJCPffcc5ozZ4527drldM5xnTp1zli3K1WqVFHfvn21cOFC5ebmym63a+nSpTp58qRTqP7111+1bdu2Ept4Wd63sLAwpw+xRX788Uc9/vjj+uSTT4o12NJ+3+eyNuBiMW3aNMXGxio8PFxRUVHq2bOnhgwZ4vjQU/RBLzY2tsTXyMrKKtafTp236Aut0wUEBEj6O7g2a9bM+oqcZvfu3cUOJZT++pBb9Pypyzs9zBetT1murSH9dT706az+7Sry66+/yhijyy+/3OXz5elCk8DFLDMzU8ePH3f5f7VRo0ZasWJFifNOmjRJ//rXv3TFFVeoWbNm6t69u26//XZdddVVZV6+q/5TEi8vL6dQK0lXXHGFJDldy+Fcy8zM1LFjx9SoUaNizzVp0kSFhYXau3evrrzySsf0s+3LuDAI1RXIgAEDtH79eo0ePVotW7aUv7+/CgsL1b1791JvB2Wz2bRkyRJt3LhRH3zwgVatWqVhw4bpmWee0caNGx2vExISogULFrh8jbJ88+ft7X3GMediOaebOnWqxo0bp2HDhmny5MmqXbu2vLy89MADD5zVbbIGDRqkl156SR999JH69Omjt99+W40bN1aLFi2c1qd58+aaMWOGy9cIDw8/43JO3YtT5MiRI+rSpYsCAgI0adIkRUZGys/PT1u2bNEjjzxSpvU6F7UBF4sBAwaoU6dOWrZsmT7++GNNnz5dTz31lJYuXaoePXo4/s9Nnz692C35ihRdz+B0RfO++eabqlu3brHny9OtVkrq4+aUi/eUxlU/s/q3q0hhYaFsNps++ugjl/WV9L4DqDg6d+6sHTt26L333tPHH3+sV155Rc8++6ySk5PLfHtZV/3nbJR0hNDpF+A93862L+PCKD9/yVGqP/74Q6mpqZo4caLGjx/vmO7OYTJt27ZV27ZtNWXKFC1cuFC33XabFi1apDvvvFORkZFas2aNOnTocM6b0qnKupwGDRpIkn777Tenbx4PHTpU7Ju5JUuW6J///KdeffVVp+lHjhxxXOxGcv/wyc6dO6tevXpKSUlRx44d9cknnziuwHvq+nz33Xe6/vrrLR+e6cq6det06NAhLV26VJ07d3ZM37VrV7GxJS33fNUGVFb16tXTyJEjNXLkSB04cEDXXHONpkyZoh49eigyMlLSX3uVo6Oj3XrdonlDQkJKnbdor8nWrVtLfT13/j83aNBAP//8c7HpRaeQFPXa88Wdv12l9TJjjC677DLHniQA5U/RHQtc/f921YdOV3Tnlbi4OP3555/q3LmzJkyY4AjV5/KzTGFhoXbu3OnUU3755RdJclw4smiP8JEjR5zmdXXYdVlrCw4OVrVq1Ursy15eXuz0qKA4p7qCKPqW6vRvpWbOnHnGef/4449i8xXtaSm6tdKAAQNUUFCgyZMnF5s/Pz+/WEOxqqzLuf7661WlShW9+OKLTmNeeOGFYvN5e3sXW7/Fixdr3759TtOK7pda1nXx8vJSv3799MEHH+jNN99Ufn6+06HfReuzb98+zZ07t9j8x48f19GjR8u0rNO5+n3n5eVpzpw5xcZWr17d5SGU56s2oLIpKCgo9n8oJCRE9evXd/TIqKgoRUZG6umnn9aff/5Z7DVKu71JTEyMAgICNHXqVJfXtSiaNzg4WJ07d9a8efO0Z88epzGn9gJ3elnPnj21adMmbdiwwTHt6NGjevnllxUREaGmTZue8TXOhjt/u0par1tuuUXe3t6aOHFisdcxxpTptpIAzj9vb2/FxMTo3Xffdeph27Zt06pVq0qd9/T/x/7+/vrHP/7hdAtQdz/HncmpnymNMXrhhRfk4+Oj66+/XtJfXzp6e3vr008/dZqvpM9iZanN29tb3bp103vvved0mHlGRoYWLlyojh07Ok4JQsXCnuoKIiAgQJ07d9a0adN08uRJhYWF6eOPP3a55/J0r7/+uubMmaObb75ZkZGRysnJ0dy5cxUQEKCePXtK+uu867vuuktJSUn69ttv1a1bN/n4+OjXX3/V4sWL9dxzz6lfv35nvR5lXU5oaKjuv/9+PfPMM7rpppvUvXt3fffdd/roo48UFBTk9I3gjTfeqEmTJikuLk7t27fXDz/8oAULFhQ7VyYyMlI1a9ZUcnKyatSooerVq6tNmzalnoMzcOBAzZo1S4mJiWrevLnjPMQit99+u95++23dfffdWrt2rTp06KCCggJt375db7/9tlatWqVWrVq5/T61b99etWrVUmxsrO677z7ZbDa9+eabLg/1iYqKUkpKihISEnTttdfK399fvXv3Pm+1AZVNTk6OLrnkEvXr108tWrSQv7+/1qxZo6+++krPPPOMpL++ZHvllVfUo0cPXXnllYqLi1NYWJj27duntWvXKiAgQB988IHL1w8ICNCLL76o22+/Xddcc40GDRqk4OBg7dmzR8uXL1eHDh0cH+6ef/55dezYUddcc41GjBihyy67TGlpaVq+fLm+/fZbSX/9n5f+uqXeoEGD5OPjo969ezs+1J3q0Ucf1VtvvaUePXrovvvuU+3atfX6669r165deueddxwXeTxf3PnbVdJ6RUZG6oknntCYMWOUlpamPn36qEaNGtq1a5eWLVumESNG6KGHHjqv6wGgbCZOnKiVK1eqU6dOGjlypPLz8zVr1ixdeeWV+v7770ucr2nTpuratauioqJUu3Ztff31147bHBYp6hH33XefYmJi5O3t7bjFqbv8/Py0cuVKxcbGqk2bNvroo4+0fPlyPfbYY45TEQMDA9W/f3/NmjVLNptNkZGR+vDDD11ek8ad2p544gmtXr1aHTt21MiRI1WlShW99NJLys3N1bRp0yytD8oBT1xyHKUr6ZZav//+u7n55ptNzZo1TWBgoOnfv7/Zv39/sUv1n347ly1btpjBgwebSy+91NjtdhMSEmJuvPFG8/XXXxdb9ssvv2yioqJM1apVTY0aNUzz5s3Nww8/bPbv319qzbGxsaZ69erFphfdZsXKcvLz8824ceNM3bp1TdWqVc11111ntm3bZurUqWPuvvtux7gTJ06Y//u//zP16tUzVatWNR06dDAbNmwwXbp0MV26dHFa7nvvvWeaNm1qqlSp4nQ7hNNvqVWksLDQhIeHG0nmiSeecLnueXl55qmnnjJXXnmlsdvtplatWiYqKspMnDjRZGVllfq+denSxVx55ZUun/viiy9M27ZtTdWqVU39+vXNww8/7LjV16m3d/jzzz/NrbfeamrWrGkkOa3H2dQGXCxyc3PN6NGjTYsWLUyNGjVM9erVTYsWLcycOXOKjf3mm2/MLbfcYurUqWPsdrtp0KCBGTBggElNTXWMOb0HF1m7dq2JiYkxgYGBxs/Pz0RGRpqhQ4cW68Vbt2519Ho/Pz/TqFEjM27cOKcxkydPNmFhYcbLy8tpWaffpsYYY3bs2GH69evneL3WrVubDz/8sFhtrv7uuLp1jCtFvb7oVjSnKuvfrtLWyxhj3nnnHdOxY0dTvXp1U716ddO4cWMzatQo8/PPP5daG4AL67///a+Jiooyvr6+pmHDhiY5ObnY58HTe9UTTzxhWrdubWrWrGmqVq1qGjdubKZMmWLy8vIcY/Lz8829995rgoODjc1mc7xeUZ+aPn16sVpKuqVW9erVzY4dO0y3bt1MtWrVTGhoqElMTCx2i9bMzEzTt29fU61aNVOrVi1z1113ma1btxZ7zZJqM6b4LbWM+euzeUxMjPH39zfVqlUz//znP8369eudxhT9LTn9lrgl3eoLnmUzhrPcUXEcOXJEtWrV0hNPPFHs/GYAAAAAuNA4pxrl1vHjx4tNKzoPr2vXrhe2GAAAAABwgXOqUW6lpKRo/vz56tmzp/z9/fX555/rrbfeUrdu3dShQwdPlwcAAAAAhGqUX1dddZWqVKmiadOmKTs723HxsieeeMLTpQEAAACAJIlzqgEAAAAAsIhzqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsqhAXKissLNT+/ftVo0YN2Ww2T5cDoIIxxignJ0f169eXl1fl+i6R/gjgbNAfAaBkZe2RFSJU79+/X+Hh4Z4uA0AFt3fvXl1yySWeLuOcoj8COBfojwBQsjP1yAoRqmvUqCHpr5UJCAjwcDUAKprs7GyFh4c7ekllQn8EcDbojwBQsrL2SEuhevbs2Zo+fbrS09PVokULzZo1S61bty5x/MyZM/Xiiy9qz549CgoKUr9+/ZSUlCQ/P78yLa/okJ2AgACaIgDLKuPhf/RHAOcC/REASnamHun2yTMpKSlKSEhQYmKitmzZohYtWigmJkYHDhxwOX7hwoV69NFHlZiYqG3btunVV19VSkqKHnvsMXcXDQAAAABAueJ2qJ4xY4aGDx+uuLg4NW3aVMnJyapWrZrmzZvncvz69evVoUMH3XrrrYqIiFC3bt00ePBgbdq06ayLBwAAAADAk9wK1Xl5edq8ebOio6P/fgEvL0VHR2vDhg0u52nfvr02b97sCNE7d+7UihUr1LNnzxKXk5ubq+zsbKcHAID+CAAloT8C8BS3QvXBgwdVUFCg0NBQp+mhoaFKT093Oc+tt96qSZMmqWPHjvLx8VFkZKS6du1a6uHfSUlJCgwMdDy4ciMA/IX+CACu0R8BeMp5vyHhunXrNHXqVM2ZM0dbtmzR0qVLtXz5ck2ePLnEecaMGaOsrCzHY+/evee7TACoEOiPAOAa/RGAp7h19e+goCB5e3srIyPDaXpGRobq1q3rcp5x48bp9ttv15133ilJat68uY4ePaoRI0Zo7NixLm+ibbfbZbfb3SntgtnWuImnSyhXmmzf5ukSgItKee6PAOBJ9EcAnuLWnmpfX19FRUUpNTXVMa2wsFCpqalq166dy3mOHTtWLDh7e3tLkowx7tYLAAAAAEC54fZ9qhMSEhQbG6tWrVqpdevWmjlzpo4ePaq4uDhJ0pAhQxQWFqakpCRJUu/evTVjxgxdffXVatOmjX777TeNGzdOvXv3doRrAAAAAAAqIrdD9cCBA5WZmanx48crPT1dLVu21MqVKx0XL9uzZ4/TnunHH39cNptNjz/+uPbt26fg4GD17t1bU6ZMOXdrAQAAAACAB9hMBTgGOzs7W4GBgcrKylJAQIBHa+GcamecU42KoDz1kHOtMq8bgPOvMveQyrxuAC6MsvaR8371bwAAAAAAKitCNQAAAAAAFrl9TjWA0nGKgDNOEQAAAEBlxp5qAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIuqeLoAAAAAALiYPTPwRk+XUO78X8qHni6hzNhTDQAAAACARYRqAAAAAAAsshSqZ8+erYiICPn5+alNmzbatGlTqeOPHDmiUaNGqV69erLb7briiiu0YsUKSwUDAAAAAFBeuH1OdUpKihISEpScnKw2bdpo5syZiomJ0c8//6yQkJBi4/Py8nTDDTcoJCRES5YsUVhYmHbv3q2aNWuei/oBAAAAAPAYt0P1jBkzNHz4cMXFxUmSkpOTtXz5cs2bN0+PPvposfHz5s3T4cOHtX79evn4+EiSIiIizq5qAAAAAADKAbcO/87Ly9PmzZsVHR399wt4eSk6OlobNmxwOc/777+vdu3aadSoUQoNDVWzZs00depUFRQUlLic3NxcZWdnOz0AAPRHACgJ/RGAp7gVqg8ePKiCggKFhoY6TQ8NDVV6errLeXbu3KklS5aooKBAK1as0Lhx4/TMM8/oiSeeKHE5SUlJCgwMdDzCw8PdKRMAKi36IwC4Rn8E4Cnn/erfhYWFCgkJ0csvv6yoqCgNHDhQY8eOVXJyconzjBkzRllZWY7H3r17z3eZAFAh0B8BwDX6IwBPceuc6qCgIHl7eysjI8NpekZGhurWretynnr16snHx0fe3t6OaU2aNFF6erry8vLk6+tbbB673S673e5OaQBwUaA/AoBr9EcAnuLWnmpfX19FRUUpNTXVMa2wsFCpqalq166dy3k6dOig3377TYWFhY5pv/zyi+rVq+cyUAMAAAAAUFG4ffh3QkKC5s6dq9dff13btm3TPffco6NHjzquBj5kyBCNGTPGMf6ee+7R4cOHdf/99+uXX37R8uXLNXXqVI0aNercrQUAAAAAAB7g9i21Bg4cqMzMTI0fP17p6elq2bKlVq5c6bh42Z49e+Tl9XdWDw8P16pVq/Tggw/qqquuUlhYmO6//3498sgj524tAAAAAADwALdDtSTFx8crPj7e5XPr1q0rNq1du3bauHGjlUUBAAAAAFBunferfwMAAAAAUFkRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkuhevbs2YqIiJCfn5/atGmjTZs2lWm+RYsWyWazqU+fPlYWCwAAAABAueJ2qE5JSVFCQoISExO1ZcsWtWjRQjExMTpw4ECp86Wlpemhhx5Sp06dLBcLAAAAAEB54naonjFjhoYPH664uDg1bdpUycnJqlatmubNm1fiPAUFBbrttts0ceJENWzY8KwKBgAAAACgvHArVOfl5Wnz5s2Kjo7++wW8vBQdHa0NGzaUON+kSZMUEhKiO+64w3qlAAAAAACUM1XcGXzw4EEVFBQoNDTUaXpoaKi2b9/ucp7PP/9cr776qr799tsyLyc3N1e5ubmOn7Ozs90pEwAqLfojALhGfwTgKef16t85OTm6/fbbNXfuXAUFBZV5vqSkJAUGBjoe4eHh57FKAKg46I8A4Br9EYCnuBWqg4KC5O3trYyMDKfpGRkZqlu3brHxO3bsUFpamnr37q0qVaqoSpUqeuONN/T++++rSpUq2rFjh8vljBkzRllZWY7H3r173SkTACot+iMAuEZ/BOApbh3+7evrq6ioKKWmpjpui1VYWKjU1FTFx8cXG9+4cWP98MMPTtMef/xx5eTk6LnnnivxG0S73S673e5OaQBwUaA/AoBr9EcAnuJWqJakhIQExcbGqlWrVmrdurVmzpypo0ePKi4uTpI0ZMgQhYWFKSkpSX5+fmrWrJnT/DVr1pSkYtMBAAAAAKho3A7VAwcOVGZmpsaPH6/09HS1bNlSK1eudFy8bM+ePfLyOq+nagMAAAAAUC64HaolKT4+3uXh3pK0bt26UuedP3++lUUCAAAAAFDuWArVAAAAAMrmmYE3erqEcuf/Uj70dAnAOcNx2gAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLLIXq2bNnKyIiQn5+fmrTpo02bdpU4ti5c+eqU6dOqlWrlmrVqqXo6OhSxwMAAAAAUFG4HapTUlKUkJCgxMREbdmyRS1atFBMTIwOHDjgcvy6des0ePBgrV27Vhs2bFB4eLi6deumffv2nXXxAAAAAAB4ktuhesaMGRo+fLji4uLUtGlTJScnq1q1apo3b57L8QsWLNDIkSPVsmVLNW7cWK+88ooKCwuVmpp61sUDAAAAAOBJVdwZnJeXp82bN2vMmDGOaV5eXoqOjtaGDRvK9BrHjh3TyZMnVbt27RLH5ObmKjc31/Fzdna2O2UCQKVFf0RFNvvuTzxdQrkyKvk6T5dQqdAfAXiKW3uqDx48qIKCAoWGhjpNDw0NVXp6eple45FHHlH9+vUVHR1d4pikpCQFBgY6HuHh4e6UCQCVFv0RAFyjPwLwlAt69e8nn3xSixYt0rJly+Tn51fiuDFjxigrK8vx2Lt37wWsEgDKL/ojALhGfwTgKW4d/h0UFCRvb29lZGQ4Tc/IyFDdunVLnffpp5/Wk08+qTVr1uiqq64qdazdbpfdbnenNAC4KNAfAcA1+iMAT3FrT7Wvr6+ioqKcLjJWdNGxdu3alTjftGnTNHnyZK1cuVKtWrWyXi0AAAAAAOWIW3uqJSkhIUGxsbFq1aqVWrdurZkzZ+ro0aOKi4uTJA0ZMkRhYWFKSkqSJD311FMaP368Fi5cqIiICMe51/7+/vL39z+HqwIAAAAAwIXldqgeOHCgMjMzNX78eKWnp6tly5ZauXKl4+Jle/bskZfX3zvAX3zxReXl5alfv35Or5OYmKgJEyacXfUAAAAAAHiQ26FakuLj4xUfH+/yuXXr1jn9nJaWZmURAAAAAACUexf06t8AAAAAAFQmlvZUAwBwutl3f+LpEsqdUcnXeboEAABwnrGnGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESoBgAAAADAIkI1AAAAAAAWEaoBAAAAALCIUA0AAAAAgEWEagAAAAAALCJUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAiwjVAAAAAABYRKgGAAAAAMAiQjUAAAAAABYRqgEAAAAAsIhQDQAAAACARZZC9ezZsxURESE/Pz+1adNGmzZtKnX84sWL1bhxY/n5+al58+ZasWKFpWIBAAAAAChP3A7VKSkpSkhIUGJiorZs2aIWLVooJiZGBw4ccDl+/fr1Gjx4sO644w5988036tOnj/r06aOtW7eedfEAAAAAAHiS26F6xowZGj58uOLi4tS0aVMlJyerWrVqmjdvnsvxzz33nLp3767Ro0erSZMmmjx5sq655hq98MILZ108AAAAAACe5FaozsvL0+bNmxUdHf33C3h5KTo6Whs2bHA5z4YNG5zGS1JMTEyJ4wEAAAAAqCiquDP44MGDKigoUGhoqNP00NBQbd++3eU86enpLsenp6eXuJzc3Fzl5uY6fs7KypIkZWdnu1PuefFnQYGnSyhXysPvpLxhG3FWHraRohqMMR6u5OyV5/54PO+op0sod8rD76U8YRtxVh62D/rjhXHi5ElPl1DulIffS3nCNlJcedhGytoj3QrVF0pSUpImTpxYbHp4eLgHqkGpAgM9XQHKu3K0jeTk5CiwHNVjBf2xYhn9mqcrQHlWnrYP+iMutMeXVeztDedfedpGztQj3QrVQUFB8vb2VkZGhtP0jIwM1a1b1+U8devWdWu8JI0ZM0YJCQmOnwsLCxUVFaUtW7bIZrO5U3KllJ2drfDwcO3du1cBAQGeLqdcuPbaa/XVV195uoxyg23EmTFGUVFRql+/vqdLOWv0x9Kx7btGj/wb24gz+uPFhe2/OPrj39g+iitrj3QrVPv6+ioqKkqpqanq06ePpL8aVmpqquLj413O065dO6WmpuqBBx5wTFu9erXatWtX4nLsdrvsdnuxaRX9G9RzLSAggA3+//P29ua9cIFt5G++vr7y8rJ0F8Fyhf5YNmz7zuiRxbGN/I3+ePFh+/8b/bE4tg9nZemRbh/+nZCQoNjYWLVq1UqtW7fWzJkzdfToUcXFxUmShgwZorCwMCUlJUmS7r//fnXp0kXPPPOMevXqpUWLFunrr7/Wyy+/7NZyR40a5W6puIiwfeBMKvM2UpnXDecG2whKU5m3j8q8bjg32EZwJmXZRmzGwpUpXnjhBU2fPl3p6elq2bKlnn/+ebVp00aS1LVrV0VERGj+/PmO8YsXL9bjjz+utLQ0XX755Zo2bZp69uzp7mLx/2VnZyswMFBZWVl8iwSX2EZwsWLbx5mwjeBixvaP0rB9WGfpQmXx8fElHu69bt26YtP69++v/v37W1kUXLDb7UpMTCx2iBNQhG0EFyu2fZwJ2wguZmz/KA3bh3WW9lQDAAAAAACp4l+VAgAAAAAADyFUAwAAAABgEaEaAAAAAACLCNUAAAAAAFhEqAYAAAAAwCJCdTm3c+dOcYF2AHCNHgkArtEfgQuHW2qVc97e3vrf//6nkJAQSdLAgQP1/PPPKzQ01MOVobwYNmxYmcbNmzfvPFcCXHj0SJSG/oiLGf0RZ0KPPHcI1eWcl5eX0tPTHQ2xRo0a+u6779SwYUMPV4bywsvLSw0aNNDVV19d6jfSy5Ytu4BVARcGPRKloT/iYkZ/xJnQI8+dKp4uAMDZueeee/TWW29p165diouL07///W/Vrl3b02UBgMfRHwGgZPTIc4dzqss5m80mm81WbBpQZPbs2frf//6nhx9+WB988IHCw8M1YMAArVq1inOpUOnRI1Ea+iMuZvRHnAk98tzh8O9yzsvLSz169JDdbpckffDBB7ruuutUvXp1p3FLly71RHkoh3bv3q358+frjTfeUH5+vn788Uf5+/t7uizgvKBHwh30R1xM6I9wFz3SOg7/LudiY2Odfv73v//toUpQUXh5eclms8kYo4KCAk+XA5xX9Ei4g/6Iiwn9Ee6iR1rHnmqgEsjNzdXSpUs1b948ff7557rxxhsVFxen7t27y8uLszwAXLzojwBQMnrkucGeaqCCGzlypBYtWqTw8HANGzZMb731loKCgjxdFgB4HP0RAEpGjzx32FMNVHBeXl669NJLdfXVV5d6ARLOmQJwsaE/AkDJ6JHnDnuqgQpuyJAhXM0TAFygPwJAyeiR5w57qgEAAAAAsIizzwEAAAAAsIhQDQAAAACARYRqAAAAAAAsIlQDAAAAAGARoRoAAAAAAIsI1QAAAAAAWESohsctWbJEzZs3V9WqVVWnTh1FR0fr6NGjkqRXXnlFTZo0kZ+fnxo3bqw5c+Y45hs2bJiuuuoq5ebmSpLy8vJ09dVXa8iQIWVa7iOPPKIrrrhC1apVU8OGDTVu3DidPHny3K8gAFhEfwQA1+iPKFcM4EH79+83VapUMTNmzDC7du0y33//vZk9e7bJyckx//nPf0y9evXMO++8Y3bu3GneeecdU7t2bTN//nxjjDE5OTmmYcOG5oEHHjDGGPPQQw+ZiIgIk5WVVaZlT5482XzxxRdm165d5v333zehoaHmqaeeOm/rCgDuoD8CgGv0R5Q3hGp41ObNm40kk5aWVuy5yMhIs3DhQqdpkydPNu3atXP8vH79euPj42PGjRtnqlSpYj777DPLtUyfPt1ERUVZnh8AziX6IwC4Rn9EeWMzxhgP7yzHRaygoEAxMTHatGmTYmJi1K1bN/Xr10++vr7y9/dX1apV5eX191kK+fn5CgwMVEZGhmPaY489pqSkJD3yyCN68skny7zslJQUPf/889qxY4f+/PNP5efnKyAgQAcOHDin6wgAVtAfAcA1+iPKG86phkd5e3tr9erV+uijj9S0aVPNmjVLjRo10tatWyVJc+fO1bfffut4bN26VRs3bnTMX1hYqC+++ELe3t767bffyrzcDRs26LbbblPPnj314Ycf6ptvvtHYsWOVl5d3ztcRAKygPwKAa/RHlDdVPF0AYLPZ1KFDB3Xo0EHjx49XgwYN9MUXX6h+/frauXOnbrvtthLnnT59urZv367//ve/iomJ0Wuvvaa4uLgzLnP9+vVq0KCBxo4d65i2e/fuc7I+AHCu0B8BwDX6I8oTQjU86ssvv1Rqaqq6deumkJAQffnll8rMzFSTJk00ceJE3XfffQoMDFT37t2Vm5urr7/+Wn/88YcSEhL0zTffaPz48VqyZIk6dOigGTNm6P7771eXLl3UsGHDUpd7+eWXa8+ePVq0aJGuvfZaLV++XMuWLbtAaw0AZ0Z/BADX6I8odzx9Ujcubj/99JOJiYkxwcHBxm63myuuuMLMmjXL8fyCBQtMy5Ytja+vr6lVq5bp3LmzWbp0qTl+/Lhp2rSpGTFihNPr3XTTTaZ9+/YmPz//jMsePXq0qVOnjvH39zcDBw40zz77rAkMDDzXqwgAltAfAcA1+iPKGy5UBgAAAACARVyoDAAAAAAAiwjVqJSmTp0qf39/l48ePXp4ujwA8Bj6IwC4Rn+EVRz+jUrp8OHDOnz4sMvnqlatqrCwsAtcEQCUD/RHAHCN/girCNUAAAAAAFjE4d8AAAAAAFhEqAYAAAAAwCJCNQAAAAAAFhGqAQAAAACwiFANAAAAAIBFhGoAAAAAACwiVAMAAAAAYBGhGgAAAAAAi/4fp3QgXTdEx2oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from fairlearn.metrics import MetricFrame, false_positive_rate, false_negative_rate, selection_rate, count\n",
    "\n",
    "def metric_frame(y_true, y_pred, sensitive):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"false positive rate\": false_positive_rate,\n",
    "        \"false negative rate\": false_negative_rate,\n",
    "        \"selection rate\": selection_rate,\n",
    "        \"distribution\": lambda t, p: count(t, p) / y_true.shape[0]\n",
    "    }\n",
    "    metric_frame = MetricFrame(\n",
    "        metrics=metrics,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        sensitive_features=sensitive\n",
    "    )\n",
    "    metric_frame.by_group.plot.bar(\n",
    "        subplots=True,\n",
    "        layout=[3, 3],\n",
    "        legend=False,\n",
    "        figsize=[12, 8],\n",
    "        sharey=True\n",
    "    )\n",
    "    \n",
    "metric_frame(y_test, y_pred > 0.5, df_pairs_test['sex_a'])\n",
    "metric_frame(yu_test, yu_pred > 0.5, df_pairs_test_uncorrelated['sex_a'])\n",
    "metric_frame(y_test, yf_pred > 0.5, df_pairs_test_uncorrelated['sex_a'])\n",
    "metric_frame(y_test, yf2_pred > 0.5, df_pairs_test_uncorrelated['sex_a'])\n",
    "\n",
    "metric_frame(y_test, y_pred > 0.5, df_pairs_test['race_a'])\n",
    "metric_frame(yu_test, yu_pred > 0.5, df_pairs_test_uncorrelated['race_a'])\n",
    "metric_frame(y_test, yf_pred > 0.5, df_pairs_test_uncorrelated['race_a'])\n",
    "metric_frame(y_test, yf2_pred > 0.5, df_pairs_test_uncorrelated['race_a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aif360.sklearn.postprocessing import CalibratedEqualizedOdds\n",
    "# import numpy as np\n",
    "# postpros = CalibratedEqualizedOdds(['sex_a', 'race_a'], 'weighted', random_state=1729)\n",
    "# postpros.fit(\n",
    "#     X=pd.concat([meta[['sex_a', 'race_a']], pd.DataFrame(y_train_pred, columns=['p'])], axis=1).set_index(['sex_a', 'race_a']),\n",
    "#     y=y\n",
    "# )\n",
    "# ypost_pred = postpros.predict_proba(pd.concat([meta_test['sex_a', 'race_a'], pd.DataFrame(y_pred, columns=['p'])]).set_index(['sex_a', 'race_a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aif360.sklearn.postprocessing import RejectOptionClassifierCV\n",
    "# postpros2 = RejectOptionClassifierCV(['sex_a', 'race_a'], scoring='average_odds')\n",
    "# postpros2.fit(\n",
    "#     pd.concat([meta[['sex_a', 'race_a']], pd.DataFrame(y_train_pred, columns=['p'])], axis=1).set_index(['sex_a', 'race_a']),\n",
    "#     y\n",
    "# )\n",
    "# ypost_pred2 = postpros2.predict_proba(\n",
    "#     pd.concat([meta_test[['sex_a', 'race_a']], pd.DataFrame(y_pred, columns=['p'])], axis=1).set_index(['sex_a', 'race_a'])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "classifier = train_classifier(X,y)\n",
    "postpros2 = ThresholdOptimizer(estimator=classifier,constraints='equalized_odds', flip=True, prefit=True)\n",
    "postpros2.fit(X,y,sensitive_features=meta[protected_columns])\n",
    "ypost_pred2 = postpros2.predict(X_test, sensitive_features=meta_test[protected_columns], random_state=1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold optimizer - acurácia: 0.60174, ROC AUC:0.5388104323753523\n"
     ]
    }
   ],
   "source": [
    "print(f'threshold optimizer - acurácia: {accuracy_score(y_test, ypost_pred2)}, ROC AUC:{roc_auc_score(y_test, ypost_pred2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_privileged = (meta['sex_a'] == 'M') & (meta['race_a'] == 'Branca')\n",
    "group_unprivileged = (meta['sex_a'] != 'M') | (meta['race_a'] != 'Branca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.bias.mitigation import CalibratedEqualizedOdds\n",
    "\n",
    "y_tpred = classifier.predict_proba(X)\n",
    "\n",
    "postpros3 = CalibratedEqualizedOdds(cost_constraint='weighted', alpha=0.5)\n",
    "postpros3.fit(y,y_tpred, group_privileged, group_unprivileged)\n",
    "ypost_pred3 = postpros3.transform(y_pred > 0.5, list(zip(1-y_pred, y_pred)), group_privileged, group_unprivileged)[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrated equalized odds - acurácia: 0.59709, ROC AUC:0.5407859844934679\n"
     ]
    }
   ],
   "source": [
    "print(f'calibrated equalized odds - acurácia: {accuracy_score(y_test, ypost_pred3)}, ROC AUC:{roc_auc_score(y_test, ypost_pred3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.bias.mitigation import LPDebiaserBinary\n",
    "\n",
    "postpros = LPDebiaserBinary(constraint='EqualizedOdds')\n",
    "postpros.fit(y,group_privileged, group_unprivileged, y_tpred > 0.5,y_tpred)\n",
    "ypost_pred = postpros.transform(group_privileged, group_unprivileged, y_pred > 0.5, list(zip(1-y_pred, y_pred)))[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpdebiaser binary - acurácia: 0.64461, ROC AUC:0.5125767565559491\n"
     ]
    }
   ],
   "source": [
    "print(f'lpdebiaser binary - acurácia: {accuracy_score(y_test, ypost_pred)}, ROC AUC:{roc_auc_score(y_test, ypost_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('sex', 'baseline', 'abs_avg_odds:', 0.07735244115572407, 'theil:', 0.5079298206539652, 'acc:', 0.60174)\",\n",
       " \"('sex', 'correlation remover', 'abs_avg_odds:', 0.0009807037477870123, 'theil:', 0.48634441563378816, 'acc:', 0.61487)\",\n",
       " \"('sex', 'reweighted', 'abs_avg_odds:', 0.07030759582283949, 'theil:', 0.5042804237299873, 'acc:', 0.60394)\",\n",
       " \"('sex', 'lp debiaser', 'abs_avg_odds:', 0.009269118143499008, 'theil:', 0.4391097962243904, 'acc:', 0.64461)\",\n",
       " \"('sex', 'threshold optimizer', 'abs_avg_odds:', 0.07735244115572407, 'theil:', 0.5079298206539652, 'acc:', 0.60174)\",\n",
       " \"('sex', 'calibrated eqodds', 'abs_avg_odds:', 0.0834403563412795, 'theil:', 0.5156874231828981, 'acc:', 0.59709)\",\n",
       " \"('race', 'baseline', 'abs_avg_odds:', 0.01714947554557364, 'theil:', 0.5079298206539652, 'acc:', 0.60174)\",\n",
       " \"('race', 'correlation remover', 'abs_avg_odds:', 0.0011225577745256204, 'theil:', 0.48634441563378816, 'acc:', 0.61487)\",\n",
       " \"('race', 'reweighted', 'abs_avg_odds:', 0.020521027988423354, 'theil:', 0.5042804237299873, 'acc:', 0.60394)\",\n",
       " \"('race', 'lp debiaser', 'abs_avg_odds:', 0.015674670321123896, 'theil:', 0.4391097962243904, 'acc:', 0.64461)\",\n",
       " \"('race', 'threshold optimizer', 'abs_avg_odds:', 0.01714947554557364, 'theil:', 0.5079298206539652, 'acc:', 0.60174)\",\n",
       " \"('race', 'calibrated eqodds', 'abs_avg_odds:', 0.017305008564595548, 'theil:', 0.5156874231828981, 'acc:', 0.59709)\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterable\n",
    "import numpy as np\n",
    "from aif360.sklearn.metrics import theil_index\n",
    "\n",
    "def absolute_avg_odds(X, y_true, y_pred) -> float:\n",
    "    return abs(y_pred[(~X) & y_true].mean() - y_pred[X & y_true].mean()) / 2 + \\\n",
    "           abs(y_pred[(~X) & (~y_true)].mean() - y_pred[X & (~y_true)].mean()) / 2\n",
    "\n",
    "def avg_predictive_value_difference(X, y_true, y_pred) -> float:\n",
    "    return y_true[(~X) & y_pred].mean() - y_true[X & y_pred].mean() / 2 + \\\n",
    "           y_true[(~X) & (~y_pred)].mean() - y_true[X & (~y_pred)].mean() / 2\n",
    "\n",
    "def get_benefit(y_true, y_pred) -> np.ndarray[int]:\n",
    "    b = y_true.astype(int) + y_pred.astype(int)\n",
    "    b = b.to_numpy()\n",
    "    return np.piecewise(b, [b != 1, b == 1], [1, 0])\n",
    "\n",
    "\n",
    "sex_privileged = df_pairs_test['sex_a'] == 'M'\n",
    "race_privileged = df_pairs_test['race_a'] == 'Branca'\n",
    "\n",
    "[\n",
    "    f\"{(ld, ly, 'abs_avg_odds:', absolute_avg_odds(d, t, p), 'theil:', theil_index(get_benefit(t,p)), 'acc:', accuracy_score(t,p))}\"\n",
    "    for (ld,d) in [('sex', sex_privileged), ('race', race_privileged)]\n",
    "    for (ly, t, p) in [('baseline', y_test, y_pred > 0.5),\n",
    "                       ('correlation remover', yu_test, yu_pred > 0.5), ('reweighted', y_test, yw_pred > 0.5),\n",
    "                    #    ('exponentiated gradient', y_test, yf_pred > 0.5), ('grid search', y_test, yf2_pred > 0.5),\n",
    "                       ('lp debiaser', y_test, ypost_pred), ('threshold optimizer', y_test, ypost_pred2),('calibrated eqodds', y_test, ypost_pred3),]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
